{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "GRU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leedhn/papago/blob/main/GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYYxqoBtTG5K"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avs2aLgeTG5M"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pandas as pd #edit\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import logging\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3wjMIEx-QFK",
        "outputId": "c2dfd1f5-be87-4089-9914-b916711342d2"
      },
      "source": [
        "from google.colab import drive #edit\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/NAVER "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/NAVER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzBh-NWo9vSz"
      },
      "source": [
        "#Logging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Nn2_fd79xSw",
        "outputId": "17d8602c-150e-4606-d651-5827a46ec280"
      },
      "source": [
        "NUM_EPOCHS = 10\n",
        "#OPTIMIZER = 'SGD'\n",
        "\n",
        "logger = logging.getLogger('my_logger')\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)\n",
        "logger.info('This message has a date/time timestamp')\n",
        "\n",
        "\n",
        "logger.propagate = False # do not pass logs to the default logger\n",
        "\n",
        "# Create handlers\n",
        "c_handler = logging.StreamHandler()\n",
        "EPOCH=10\n",
        "f_handler = logging.FileHandler(f'GRU_{NUM_EPOCHS}.log', mode='w')\n",
        "c_handler.setLevel(logging.INFO)\n",
        "f_handler.setLevel(logging.INFO)\n",
        "\n",
        "# Create formatters and add it to handlers\n",
        "c_format = logging.Formatter('%(asctime)s - %(message)s')\n",
        "f_format = logging.Formatter('%(asctime)s - %(message)s')\n",
        "c_handler.setFormatter(c_format)\n",
        "f_handler.setFormatter(f_format)\n",
        "\n",
        "# Add handlers to the logger\n",
        "logger.addHandler(c_handler)\n",
        "logger.addHandler(f_handler)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-10 13:09:17,217 - This message has a date/time timestamp\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQdNgJZUTG5M"
      },
      "source": [
        "#데이터 파일 로딩\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8V40ElwTG5N"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "# class Lang:\n",
        "#     def __init__(self, name):\n",
        "#         self.name = name\n",
        "#         self.word2index = {}\n",
        "#         self.word2count = {}\n",
        "#         self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "#         self.n_words = 2  # SOS 와 EOS 포함\n",
        "\n",
        "#     def addSentence(self, sentence):\n",
        "#         for word in sentence.split(' '):\n",
        "#             self.addWord(word)\n",
        "\n",
        "#     def addWord(self, word):\n",
        "#         if word not in self.word2index:\n",
        "#             self.word2index[word] = self.n_words\n",
        "#             self.word2count[word] = 1\n",
        "#             self.index2word[self.n_words] = word\n",
        "#             self.n_words += 1\n",
        "#         else:\n",
        "#             self.word2count[word] += 1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qykuSzcBTG5N"
      },
      "source": [
        "# 유니 코드 문자열을 일반 ASCII로 변환하십시오.\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "# def unicodeToAscii(s):\n",
        "#     return ''.join(\n",
        "#         c for c in unicodedata.normalize('NFD', s)\n",
        "#         if unicodedata.category(c) != 'Mn'\n",
        "#     )\n",
        "\n",
        "# # 소문자, 다듬기, 그리고 문자가 아닌 문자 제거\n",
        "\n",
        "\n",
        "# def normalizeString(s):\n",
        "#     s = unicodeToAscii(s.lower().strip())\n",
        "#     s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "#     s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "#     return s"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgpUIsydTG5N"
      },
      "source": [
        "# def readLangs(lang1, lang2, reverse=False):\n",
        "#     print(\"Reading lines...\")\n",
        "\n",
        "#     # 파일을 읽고 줄로 분리\n",
        "#     lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "#         read().strip().split('\\n')\n",
        "\n",
        "#     # 모든 줄을 쌍으로 분리하고 정규화\n",
        "#     pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "#     # 쌍을 뒤집고, Lang 인스턴스 생성\n",
        "#     if reverse:\n",
        "#         pairs = [list(reversed(p)) for p in pairs]\n",
        "#         input_lang = Lang(lang2)\n",
        "#         output_lang = Lang(lang1)\n",
        "#     else:\n",
        "#         input_lang = Lang(lang1)\n",
        "#         output_lang = Lang(lang2)\n",
        "\n",
        "#     return input_lang, output_lang, pairs"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZHd04yXTG5N"
      },
      "source": [
        "MAX_LENGTH = 100\n",
        "\n",
        "# eng_prefixes = (\n",
        "#     \"i am \", \"i m \",\n",
        "#     \"he is\", \"he s \",\n",
        "#     \"she is\", \"she s \",\n",
        "#     \"you are\", \"you re \",\n",
        "#     \"we are\", \"we re \",\n",
        "#     \"they are\", \"they re \"\n",
        "# )\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlRnQ9J5TG5O"
      },
      "source": [
        "데이터 준비를 위한 전체 과정:\n",
        "\n",
        "-  텍스트 파일을 읽고 줄로 분리하고, 줄을 쌍으로 분리합니다.\n",
        "-  텍스트를 정규화 하고 길이와 내용으로 필터링 합니다.\n",
        "-  쌍을 이룬 문장들로 단어 리스트를 생성합니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HPaqu-L-d_C",
        "outputId": "10272474-1491-4011-ce84-71f6803fe46b"
      },
      "source": [
        "logger.info('='*50)\n",
        "logger.info('LOADING DATA')\n",
        "logger.info('')\n",
        "\n",
        "%cd data\n",
        "txt_list = glob('*.txt') #edit\n",
        "datas = {}\n",
        "for txt in txt_list:\n",
        "    datas[txt] = pd.read_csv(txt,header=None)\n",
        "    name = txt[-10:-4]\n",
        "    datas[txt].columns = [name]\n",
        "    for i in range(len(datas[txt][name])):\n",
        "        datas[txt][name][i] = np.fromstring(datas[txt][name][i] ,dtype=int,sep=' ').tolist()\n",
        "        datas[txt][name][i].append(1)\n",
        "    logger.info(f'Load {txt} finished')\n",
        "%cd ../\n",
        "logger.info('='*50)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-10 13:09:17,262 - ==================================================\n",
            "2021-06-10 13:09:17,264 - LOADING DATA\n",
            "2021-06-10 13:09:17,267 - \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/NAVER/data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-06-10 13:09:18,102 - Load train_source.txt finished\n",
            "2021-06-10 13:09:18,916 - Load train_target.txt finished\n",
            "2021-06-10 13:09:19,083 - Load test_target.txt finished\n",
            "2021-06-10 13:09:19,232 - Load test_source.txt finished\n",
            "2021-06-10 13:09:19,235 - ==================================================\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/NAVER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olwJObpiTG5O"
      },
      "source": [
        "# def prepareData(lang1, lang2, reverse=False):\n",
        "#     input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "#     print(\"Read %s sentence pairs\" % len(pairs))\n",
        "#     pairs = filterPairs(pairs)\n",
        "#     print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "#     print(\"Counting words...\")\n",
        "#     for pair in pairs:\n",
        "#         input_lang.addSentence(pair[0])\n",
        "#         output_lang.addSentence(pair[1])\n",
        "#     print(\"Counted words:\")\n",
        "#     print(input_lang.name, input_lang.n_words)\n",
        "#     print(output_lang.name, output_lang.n_words)\n",
        "#     return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "# input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "# print(random.choice(pairs))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TknIbSoETG5O"
      },
      "source": [
        "Seq2Seq 모델\n",
        "=================\n",
        "\n",
        "Recurrent Neural Network(RNN)는 시퀀스에서 작동하고 다음 단계의\n",
        "입력으로 자신의 출력을 사용하는 네트워크입니다.\n",
        "\n",
        "`Sequence to Sequence network <https://arxiv.org/abs/1409.3215>`__, 또는\n",
        "Seq2Seq 네트워크, 또는 `Encoder Decoder\n",
        "network <https://arxiv.org/pdf/1406.1078v3.pdf>`__ 는 인코더 및\n",
        "디코더라고 하는 두 개의 RNN으로 구성된 모델입니다.\n",
        "인코더는 입력 시퀀스를 읽고 단일 벡터를 출력하고,\n",
        "디코더는 해당 벡터를 읽어 출력 시퀀스를 생성합니다.\n",
        "\n",
        ".. figure:: /_static/img/seq-seq-images/seq2seq.png\n",
        "   :alt:\n",
        "\n",
        "모든 입력에 해당하는 출력이 있는 단일 RNN의 시퀀스 예측과 달리\n",
        "Seq2Seq 모델은 시퀀스 길이와 순서를 자유롭게하기 때문에\n",
        "두 언어 사이의 번역에 이상적입니다.\n",
        "\n",
        "다음 문장 \"Je ne suis pas le chat noir\" → \"I am not the black cat\"\n",
        "를 살펴 봅시다. 입력 문장의 단어 대부분은 출력 문장에서\n",
        "직역(\"chat noir\" 와 \"black cat\")되지만 약간 다른 순서도 있습니다.\n",
        "\"ne/pas\" 구조로 인해 입력 문장에 단어가 하나 더 있습니다.\n",
        "입력 단어의 시퀀스를 직역해서 정확한 번역을 만드는\n",
        "것은 어려울 것입니다.\n",
        "\n",
        "Seq2Seq 모델을 사용하면 인코더는 하나의 벡터를 생성합니다.\n",
        "이상적인 경우에 입력 시퀀스의 \"의미\"를 문장의 N 차원 공간에 있는\n",
        "단일 지점인 단일 벡터으로 인코딩합니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxycvMllTG5P"
      },
      "source": [
        "인코더\n",
        "-----------\n",
        "\n",
        "Seq2Seq 네트워크의 인코더는 입력 문장의 모든 단어에 대해 어떤 값을\n",
        "출력하는 RNN입니다. 모든 입력 단어에 대해 인코더는 벡터와\n",
        "은닉 상태를 출력하고 다음 입력 단어를 위해 그 은닉 상태를 사용합니다.\n",
        "\n",
        ".. figure:: /_static/img/seq-seq-images/encoder-network.png\n",
        "   :alt:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4vLE-HxTG5P"
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddyf4mH0TG5Q"
      },
      "source": [
        "디코더\n",
        "-----------\n",
        "\n",
        "디코더는 인코더 출력 벡터를 받아서 번역을 생성하기 위한 단어 시퀀스를\n",
        "출력합니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlazqhOiTG5Q"
      },
      "source": [
        "간단한 디코더\n",
        "^^^^^^^^^^^^^^\n",
        "\n",
        "가장 간단한 Seq2Seq 디코더는 인코더의 마지막 출력만을 이용합니다.\n",
        "이 마지막 출력은 전체 시퀀스에서 문맥을 인코드하기 때문에\n",
        "*문맥 벡터(context vector)* 로 불립니다. 이 문맥 벡터는 디코더의 초기 은닉 상태로\n",
        "사용 됩니다.\n",
        "\n",
        "디코딩의 매 단계에서 디코더에게 입력 토큰과 은닉 상태가 주어집니다.\n",
        "초기 입력 토큰은 문자열-시작 (start-of-string) ``<SOS>`` 토큰이고,\n",
        "첫 은닉 상태는 문맥 벡터(인코더의 마지막 은닉 상태) 입니다.\n",
        "\n",
        ".. figure:: /_static/img/seq-seq-images/decoder-network.png\n",
        "   :alt:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afTXJqGKTG5Q"
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYv_xIc_TG5Q"
      },
      "source": [
        "이 모델의 결과를 학습하고 관찰하는 것을 권장하지만,\n",
        "공간을 절약하기 위해 최종 목적지로 바로 이동해서\n",
        "Attention 메카니즘을 소개 할 것입니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlkT7krwTG5Q"
      },
      "source": [
        "Attention 디코더\n",
        "^^^^^^^^^^^^^^^^^\n",
        "\n",
        "문맥 벡터만 인코더와 디코더 사이로 전달 된다면, 단일 벡터가 전체 문장을\n",
        "인코딩 해야하는 부담을 가지게 됩니다.\n",
        "\n",
        "Attention은 디코더 네트워크가 자기 출력의 모든 단계에서 인코더 출력의\n",
        "다른 부분에 \"집중\" 할 수 있게 합니다. 첫째 *Attention 가중치* 의 세트를\n",
        "계산합니다. 이것은 가중치 조합을 만들기 위해서 인코더 출력 벡터와\n",
        "곱해집니다. 그 결과(코드에서 ``attn_applied``)는 입력 시퀀스의\n",
        "특정 부분에 관한 정보를 포함해야하고 따라서 디코더가 알맞은 출력\n",
        "단어를 선택하는 것을 도와줍니다.\n",
        "\n",
        ".. figure:: https://i.imgur.com/1152PYf.png\n",
        "   :alt:\n",
        "\n",
        "어텐션 가중치 계산은 디코더의 입력 및 은닉 상태를 입력으로\n",
        "사용하는 다른 feed-forwad 계층인 ``attn`` 으로 수행됩니다.\n",
        "학습 데이터에는 모든 크기의 문장이 있기 때문에 이 계층을 실제로\n",
        "만들고 학습시키려면 적용 할 수 있는 최대 문장 길이 (인코더 출력을 위한 입력 길이)를\n",
        "선택해야 합니다. 최대 길이의 문장은 모든 Attention 가중치를 사용하지만\n",
        "더 짧은 문장은 처음 몇 개만 사용합니다.\n",
        "\n",
        ".. figure:: /_static/img/seq-seq-images/attention-decoder-network.png\n",
        "   :alt:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfvKm3x7TG5Q"
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYcHQ4lXTG5R"
      },
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>There are other forms of attention that work around the length\n",
        "  limitation by using a relative position approach. Read about \"local\n",
        "  attention\" in `Effective Approaches to Attention-based Neural Machine\n",
        "  Translation <https://arxiv.org/abs/1508.04025>`__.</p></div>\n",
        "\n",
        "학습\n",
        "========\n",
        "\n",
        "학습 데이터 준비\n",
        "-----------------------\n",
        "\n",
        "학습을 위해서, 각 쌍마다 입력 Tensor(입력 문장의 단어 주소)와\n",
        "목표 Tensor(목표 문장의 단어 주소)가 필요합니다. 이 벡터들을\n",
        "생성하는 동안 두 시퀀스에 EOS 토큰을 추가 합니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9OwFzoHTG5R"
      },
      "source": [
        "# def indexesFromSentence(lang, sentence):\n",
        "#     return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "# def tensorFromSentence(lang, sentence):\n",
        "#     indexes = indexesFromSentence(lang, sentence)\n",
        "#     indexes.append(EOS_token)\n",
        "#     return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "# def tensorsFromPair(pair):\n",
        "#     input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "#     target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "#     return (input_tensor, target_tensor)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0DuUYbvTG5R"
      },
      "source": [
        "모델 학습\n",
        "------------------\n",
        "\n",
        "학습을 위해서 인코더에 입력 문장을 넣고 모든 출력과 최신 은닉 상태를\n",
        "추적합니다. 그런 다음 디코더에 첫 번째 입력으로 ``<SOS>`` 토큰과\n",
        "인코더의 마지막 은닉 상태가 첫번쩨 은닉 상태로 제공됩니다.\n",
        "\n",
        "\"Teacher forcing\"은 다음 입력으로 디코더의 예측을 사용하는 대신\n",
        "실제 목표 출력을 다음 입력으로 사용하는 컨셉입니다.\n",
        "\"Teacher forcing\"을 사용하면 수렴이 빨리되지만 `학습된 네트워크가\n",
        "잘못 사용될 때 불안정성을 보입니다.\n",
        "<http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.378.4095&rep=rep1&type=pdf>`__.\n",
        "\n",
        "Teacher-forced 네트워크의 출력이 일관된 문법으로 읽지만 정확한\n",
        "번역과는 거리가 멀다는 것을 볼 수 있습니다. 직관적으로 출력 문법을\n",
        "표현하는 법을 배우고 교사가 처음 몇 단어를 말하면 의미를 \"선택\" 할 수 있지만,\n",
        "번역에서 처음으로 문장을 만드는 법은 잘 배우지 못합니다.\n",
        "\n",
        "PyTorch의 autograd 가 제공하는 자유 덕분에 간단한 If 문으로\n",
        "Teacher Forcing을 사용할지 아니면 사용하지 않을지를 선택할 수 있습니다.\n",
        "더 많이 사용하려면 ``teacher_forcing_ratio`` 를 확인하십시오.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_b3GfdOkTG5R"
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "MAX_LENGTH=100\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "    encoder_hidden.to(device)\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "        \n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing 포함: 목표를 다음 입력으로 전달\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Teacher forcing 미포함: 자신의 예측을 다음 입력으로 사용\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # 입력으로 사용할 부분을 히스토리에서 분리\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z04EgrZ8TG5R"
      },
      "source": [
        "이것은 현재 시간과 진행률%을 고려해 경과된 시간과 남은 예상\n",
        "시간을 출력하는 헬퍼 함수입니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67KvZvI_TG5S"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeIcRO5TTG5S"
      },
      "source": [
        "전체 학습 과정은 다음과 같습니다:\n",
        "\n",
        "-  타이머 시작\n",
        "-  optimizers와 criterion 초기화\n",
        "-  학습 쌍의 세트 생성\n",
        "-  도식화를 위한 빈 손실 배열 시작\n",
        "\n",
        "그런 다음 우리는 여러 번 ``train`` 을 호출하며 때로는 진행률\n",
        "(예제의 %, 현재까지의 예상 시간)과 평균 손실을 출력합니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vcIBXdeJuvh"
      },
      "source": [
        "# source_words = []\n",
        "# for line in datas['train_source.txt']['source']:\n",
        "#     for num in line:\n",
        "#         if num not in source_words:\n",
        "#             source_words.append(num)\n",
        "\n",
        "# len(source_words)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ_StldUTG5S"
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters,logger, epochs, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # print_every 마다 초기화\n",
        "    plot_loss_total = 0  # plot_every 마다 초기화\n",
        "    learning_rate = 0.001\n",
        "    # encoder.train()\n",
        "    # decoder.train()\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    # encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    # decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "    # 옵티마이저의 state_dict 출력\n",
        "    logger.info('Encoder Optimizer state_dict:')\n",
        "    for var_name in encoder_optimizer.state_dict():\n",
        "        logger.info(f'{var_name} \\t {encoder_optimizer.state_dict()[var_name]}')\n",
        "    logger.info('Decoder Optimizer state_dict:')\n",
        "    for var_name in decoder_optimizer.state_dict():\n",
        "        logger.info(f'{var_name} \\t {decoder_optimizer.state_dict()[var_name]}')\n",
        "\n",
        "    \n",
        "    # training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "    #                   for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    logger.info('='*50)\n",
        "    logger.info('TRAIN')\n",
        "    logger.info('-'*50)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        encoder.train()\n",
        "        decoder.train()\n",
        "        \n",
        "        logger.info(f'EPOCH : {epoch}')\n",
        "        logger.info('-'*30)\n",
        "        for iter in range(1, n_iters + 1):\n",
        "        ##for iter in range(0, niters):\n",
        "            # training_pair = training_pairs[iter - 1]\n",
        "            # input_tensor = training_pair[0]\n",
        "            # target_tensor = training_pair[1]\n",
        "            input_list = datas['train_source.txt']['source'][iter-1]\n",
        "            #input_list.append(EOS_token)\n",
        "\n",
        "            target_list = datas['train_target.txt']['target'][iter-1]\n",
        "            #target_list.append(EOS_token)\n",
        "            input_tensor = torch.Tensor(input_list).type(torch.long).unsqueeze(1)\n",
        "            input_tensor =input_tensor.to(device)\n",
        "            target_tensor = torch.Tensor(target_list).type(torch.long).unsqueeze(1)\n",
        "            target_tensor = target_tensor.to(device)\n",
        "            # input_tensor = source_data[iter-1]\n",
        "            # input_tensor = input_tensor.to(device)\n",
        "            # target_tensor = target_data[iter-1]\n",
        "            # target_tensor = target_tensor.to(device)\n",
        "            # #print(input_tensor)\n",
        "            #return\n",
        "\n",
        "            loss = train(input_tensor, target_tensor, encoder,\n",
        "                        decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "            print_loss_total += loss\n",
        "            plot_loss_total += loss\n",
        "\n",
        "            if iter % print_every == 0:\n",
        "                print_loss_avg = print_loss_total / print_every\n",
        "                print_loss_total = 0\n",
        "                # print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                #                             iter, iter / n_iters * 100, print_loss_avg))\n",
        "                logger.info( f'{(timeSince(start, iter / n_iters))} ({iter} {int(iter / n_iters * 100)}%) {print_loss_avg}')\n",
        "            if iter % plot_every == 0:\n",
        "                plot_loss_avg = plot_loss_total / plot_every\n",
        "                plot_losses.append(plot_loss_avg)\n",
        "                plot_loss_total = 0\n",
        "\n",
        "        \n",
        "        showPlot(plot_losses)\n",
        "        evaluateRandomly(encoder1, attn_decoder1)\n",
        "    return plot_losses"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJXRAYykTG5T"
      },
      "source": [
        "결과 도식화\n",
        "----------------\n",
        "\n",
        "matplotlib로 학습 중에 저장된 손실 값 ``plot_losses`` 의 배열을\n",
        "사용하여 도식화합니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hXtrYl1TG5U"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # 주기적인 간격에 이 locator가 tick을 설정\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n",
        "    plt.show()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKikTvfiTG5W"
      },
      "source": [
        "평가\n",
        "==========\n",
        "\n",
        "평가는 대부분 학습과 동일하지만 목표가 없으므로 각 단계마다 디코더의\n",
        "예측을 되돌려 전달합니다.\n",
        "단어를 예측할 때마다 그 단어를 출력 문자열에 추가합니다.\n",
        "만약 EOS 토큰을 예측하면 거기에서 멈춥니다.\n",
        "나중에 도식화를 위해서 디코더의 Attention 출력을 저장합니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXccD3TnTG5W"
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        encoder.eval()\n",
        "        decoder.eval()\n",
        "        #input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_tensor = sentence.to(device)#datas['test_source.txt']\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            # if topi.item() == EOS_token:\n",
        "            #     decoded_words.append('<EOS>')\n",
        "            #     break\n",
        "            # else:\n",
        "            #     decoded_words.append(output_lang.index2word[topi.item()])\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append(1)\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(topi.item())\n",
        "\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOLRnm3OTG5W"
      },
      "source": [
        "학습 세트에 있는 임의의 문장을 평가하고\n",
        "입력, 목표 및 출력을 출력하여 주관적인 품질 판단을 내릴 수 있습니다:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGat_RzQTG5W"
      },
      "source": [
        "import random\n",
        "def evaluateRandomly(encoder, decoder, n=1):#10):\n",
        "    for i in range(n):\n",
        "        ran = random.randrange(1,len(datas['test_source.txt']))\n",
        "        pair = [datas['test_source.txt']['source'][ran], datas['test_target.txt']['target'][ran]]\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, torch.Tensor(pair[0]).type(torch.long).unsqueeze(1))\n",
        "        #output_sentence = ' '.join(output_words)\n",
        "        print('<',output_words)\n",
        "        #print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyDYiRtITG5W"
      },
      "source": [
        "학습과 평가\n",
        "=======================\n",
        "\n",
        "이러한 모든 헬퍼 함수를 이용해서 (추가 작업처럼 보이지만 여러 실험을\n",
        "더 쉽게 수행 할 수 있음) 실제로 네트워크를 초기화하고 학습을\n",
        "시작할 수 있습니다.\n",
        "\n",
        "입력 문장이 많이 필터링되었음을 기억하십시오. 이 작은 데이터 세트의\n",
        "경우 256 크기의 은닉 노드(hidden node)와 단일 GRU 계층 같은 상대적으로 작은\n",
        "네트워크를 사용할 수 있습니다. MacBook CPU에서 약 40분 후에\n",
        "합리적인 결과를 얻을 것입니다.\n",
        "\n",
        ".. Note::\n",
        "   이 노트북을 실행하면 학습, 커널 중단, 평가를 할 수 있고 나중에\n",
        "   이어서 학습을 할 수 있습니다. 인코더와 디코더가 초기화 된 행을\n",
        "   주석 처리하고 ``trainIters`` 를 다시 실행하십시오.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT8Qz87aNEwX"
      },
      "source": [
        "#device = 'cpu'\n",
        "EPOCHS = 10"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UpkIcSSTHlo",
        "outputId": "d5b690ce-7eac-4ef3-b54f-8a34424981a4"
      },
      "source": [
        "hidden_size = 256\n",
        "#encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "#attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "encoder1 = EncoderRNN(700, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, 700, dropout_p=0.1).to(device)\n",
        "\n",
        "\n",
        "\n",
        "# 모델의 state_dict 출력\n",
        "logger.info(\"ENCODER's state_dict:\")\n",
        "for param_tensor in encoder1.state_dict():\n",
        "    logger.info(f\"{param_tensor}\\t {encoder1.state_dict()[param_tensor].size()}\")\n",
        "\n",
        "logger.info(\"DECODER's state_dict:\")\n",
        "for param_tensor in attn_decoder1.state_dict():\n",
        "    logger.info(f\"{param_tensor}\\t {attn_decoder1.state_dict()[param_tensor].size()}\")\n",
        "\n",
        "\n",
        "\n",
        "plot_losses = trainIters(encoder1, attn_decoder1,  len(datas['train_source.txt']), print_every=100, logger=logger,epochs=EPOCHS)\n",
        "logger.info(\"TRAIN FINISHED\")\n",
        "logger.info('='*50)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-10 13:29:23,940 - ENCODER's state_dict:\n",
            "2021-06-10 13:29:23,942 - embedding.weight\t torch.Size([700, 256])\n",
            "2021-06-10 13:29:23,944 - gru.weight_ih_l0\t torch.Size([768, 256])\n",
            "2021-06-10 13:29:23,946 - gru.weight_hh_l0\t torch.Size([768, 256])\n",
            "2021-06-10 13:29:23,948 - gru.bias_ih_l0\t torch.Size([768])\n",
            "2021-06-10 13:29:23,949 - gru.bias_hh_l0\t torch.Size([768])\n",
            "2021-06-10 13:29:23,950 - DECODER's state_dict:\n",
            "2021-06-10 13:29:23,953 - embedding.weight\t torch.Size([700, 256])\n",
            "2021-06-10 13:29:23,955 - attn.weight\t torch.Size([100, 512])\n",
            "2021-06-10 13:29:23,957 - attn.bias\t torch.Size([100])\n",
            "2021-06-10 13:29:23,959 - attn_combine.weight\t torch.Size([256, 512])\n",
            "2021-06-10 13:29:23,961 - attn_combine.bias\t torch.Size([256])\n",
            "2021-06-10 13:29:23,963 - gru.weight_ih_l0\t torch.Size([768, 256])\n",
            "2021-06-10 13:29:23,964 - gru.weight_hh_l0\t torch.Size([768, 256])\n",
            "2021-06-10 13:29:23,966 - gru.bias_ih_l0\t torch.Size([768])\n",
            "2021-06-10 13:29:23,968 - gru.bias_hh_l0\t torch.Size([768])\n",
            "2021-06-10 13:29:23,970 - out.weight\t torch.Size([700, 256])\n",
            "2021-06-10 13:29:23,971 - out.bias\t torch.Size([700])\n",
            "2021-06-10 13:29:23,973 - Encoder Optimizer state_dict:\n",
            "2021-06-10 13:29:23,974 - state \t {}\n",
            "2021-06-10 13:29:23,977 - param_groups \t [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4]}]\n",
            "2021-06-10 13:29:23,978 - Decoder Optimizer state_dict:\n",
            "2021-06-10 13:29:23,979 - state \t {}\n",
            "2021-06-10 13:29:23,981 - param_groups \t [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}]\n",
            "2021-06-10 13:29:23,982 - ==================================================\n",
            "2021-06-10 13:29:23,984 - TRAIN\n",
            "2021-06-10 13:29:23,985 - --------------------------------------------------\n",
            "2021-06-10 13:29:23,987 - EPOCH : 0\n",
            "2021-06-10 13:29:23,989 - ------------------------------\n",
            "2021-06-10 13:29:26,844 - 0m 2s (- 3m 25s) (100 1%) 5.967915455763398\n",
            "2021-06-10 13:29:29,566 - 0m 5s (- 3m 17s) (200 2%) 5.178208055150109\n",
            "2021-06-10 13:29:32,325 - 0m 8s (- 3m 13s) (300 4%) 4.762690904238305\n",
            "2021-06-10 13:29:35,185 - 0m 11s (- 3m 12s) (400 5%) 4.55293493950276\n",
            "2021-06-10 13:29:38,197 - 0m 14s (- 3m 12s) (500 6%) 4.297857868236514\n",
            "2021-06-10 13:29:41,097 - 0m 17s (- 3m 10s) (600 8%) 4.356060626265228\n",
            "2021-06-10 13:29:43,804 - 0m 19s (- 3m 5s) (700 9%) 4.372474109236111\n",
            "2021-06-10 13:29:46,750 - 0m 22s (- 3m 3s) (800 11%) 4.318150550611197\n",
            "2021-06-10 13:29:49,487 - 0m 25s (- 3m 0s) (900 12%) 4.309356160819124\n",
            "2021-06-10 13:29:52,242 - 0m 28s (- 2m 56s) (1000 13%) 4.259005809741918\n",
            "2021-06-10 13:29:54,795 - 0m 30s (- 2m 52s) (1100 15%) 4.2575348156211215\n",
            "2021-06-10 13:29:57,528 - 0m 33s (- 2m 49s) (1200 16%) 4.249123635752191\n",
            "2021-06-10 13:30:00,516 - 0m 36s (- 2m 47s) (1300 17%) 4.2727087152476315\n",
            "2021-06-10 13:30:03,406 - 0m 39s (- 2m 45s) (1400 19%) 4.196947081248912\n",
            "2021-06-10 13:30:06,515 - 0m 42s (- 2m 43s) (1500 20%) 4.13902251447905\n",
            "2021-06-10 13:30:09,239 - 0m 45s (- 2m 40s) (1600 22%) 4.142314041662245\n",
            "2021-06-10 13:30:11,864 - 0m 47s (- 2m 36s) (1700 23%) 4.132316851090952\n",
            "2021-06-10 13:30:14,351 - 0m 50s (- 2m 32s) (1800 24%) 4.134482689878839\n",
            "2021-06-10 13:30:16,963 - 0m 52s (- 2m 29s) (1900 26%) 4.161810115146608\n",
            "2021-06-10 13:30:19,824 - 0m 55s (- 2m 26s) (2000 27%) 4.1909494520135455\n",
            "2021-06-10 13:30:22,321 - 0m 58s (- 2m 23s) (2100 28%) 4.107563837323483\n",
            "2021-06-10 13:30:25,127 - 1m 1s (- 2m 20s) (2200 30%) 4.136293997957686\n",
            "2021-06-10 13:30:27,627 - 1m 3s (- 2m 17s) (2300 31%) 4.132048025530916\n",
            "2021-06-10 13:30:30,582 - 1m 6s (- 2m 14s) (2400 33%) 4.14215781603186\n",
            "2021-06-10 13:30:33,397 - 1m 9s (- 2m 12s) (2500 34%) 4.025610836012769\n",
            "2021-06-10 13:30:35,844 - 1m 11s (- 2m 8s) (2600 35%) 4.102747512863905\n",
            "2021-06-10 13:30:38,703 - 1m 14s (- 2m 6s) (2700 37%) 3.925276418148308\n",
            "2021-06-10 13:30:41,450 - 1m 17s (- 2m 3s) (2800 38%) 4.088150919452161\n",
            "2021-06-10 13:30:44,009 - 1m 20s (- 2m 0s) (2900 39%) 4.031639848333339\n",
            "2021-06-10 13:30:46,853 - 1m 22s (- 1m 57s) (3000 41%) 3.961353456655303\n",
            "2021-06-10 13:30:49,564 - 1m 25s (- 1m 54s) (3100 42%) 4.027054390658235\n",
            "2021-06-10 13:30:52,163 - 1m 28s (- 1m 51s) (3200 44%) 3.8803788459817037\n",
            "2021-06-10 13:30:55,008 - 1m 31s (- 1m 49s) (3300 45%) 3.9464713979691726\n",
            "2021-06-10 13:30:57,802 - 1m 33s (- 1m 46s) (3400 46%) 3.932995593242625\n",
            "2021-06-10 13:31:00,571 - 1m 36s (- 1m 43s) (3500 48%) 3.9447275353129685\n",
            "2021-06-10 13:31:03,413 - 1m 39s (- 1m 41s) (3600 49%) 3.933612936329469\n",
            "2021-06-10 13:31:05,887 - 1m 41s (- 1m 38s) (3700 50%) 3.910601162358584\n",
            "2021-06-10 13:31:08,673 - 1m 44s (- 1m 35s) (3800 52%) 3.9477055733772817\n",
            "2021-06-10 13:31:11,430 - 1m 47s (- 1m 32s) (3900 53%) 3.7504997059670147\n",
            "2021-06-10 13:31:14,022 - 1m 50s (- 1m 29s) (4000 55%) 3.809418970877357\n",
            "2021-06-10 13:31:16,920 - 1m 52s (- 1m 27s) (4100 56%) 3.7416291708019123\n",
            "2021-06-10 13:31:19,476 - 1m 55s (- 1m 24s) (4200 57%) 3.7338686857063594\n",
            "2021-06-10 13:31:22,273 - 1m 58s (- 1m 21s) (4300 59%) 3.8393894243508258\n",
            "2021-06-10 13:31:24,584 - 2m 0s (- 1m 18s) (4400 60%) 3.7040537409783405\n",
            "2021-06-10 13:31:27,287 - 2m 3s (- 1m 15s) (4500 61%) 3.7248256100525055\n",
            "2021-06-10 13:31:29,883 - 2m 5s (- 1m 12s) (4600 63%) 3.660224268291455\n",
            "2021-06-10 13:31:32,842 - 2m 8s (- 1m 10s) (4700 64%) 3.62239804104516\n",
            "2021-06-10 13:31:35,828 - 2m 11s (- 1m 7s) (4800 66%) 3.6909678392136156\n",
            "2021-06-10 13:31:38,544 - 2m 14s (- 1m 4s) (4900 67%) 3.644121526776201\n",
            "2021-06-10 13:31:41,299 - 2m 17s (- 1m 2s) (5000 68%) 3.726334017274947\n",
            "2021-06-10 13:31:43,877 - 2m 19s (- 0m 59s) (5100 70%) 3.6361545928770096\n",
            "2021-06-10 13:31:46,155 - 2m 22s (- 0m 56s) (5200 71%) 3.4879617051556897\n",
            "2021-06-10 13:31:48,583 - 2m 24s (- 0m 53s) (5300 73%) 3.731896052197909\n",
            "2021-06-10 13:31:51,108 - 2m 27s (- 0m 50s) (5400 74%) 3.6689708831652057\n",
            "2021-06-10 13:31:53,866 - 2m 29s (- 0m 47s) (5500 75%) 3.6041792077708745\n",
            "2021-06-10 13:31:56,333 - 2m 32s (- 0m 45s) (5600 77%) 3.6048342171515744\n",
            "2021-06-10 13:31:58,947 - 2m 34s (- 0m 42s) (5700 78%) 3.5892538865210044\n",
            "2021-06-10 13:32:01,601 - 2m 37s (- 0m 39s) (5800 79%) 3.5181079675778073\n",
            "2021-06-10 13:32:04,365 - 2m 40s (- 0m 36s) (5900 81%) 3.4254335897603836\n",
            "2021-06-10 13:32:07,102 - 2m 43s (- 0m 34s) (6000 82%) 3.6353604029856768\n",
            "2021-06-10 13:32:09,643 - 2m 45s (- 0m 31s) (6100 84%) 3.7446935479999026\n",
            "2021-06-10 13:32:12,046 - 2m 48s (- 0m 28s) (6200 85%) 3.661058279935122\n",
            "2021-06-10 13:32:14,927 - 2m 50s (- 0m 26s) (6300 86%) 3.717324480408108\n",
            "2021-06-10 13:32:17,468 - 2m 53s (- 0m 23s) (6400 88%) 3.6076846793771806\n",
            "2021-06-10 13:32:20,376 - 2m 56s (- 0m 20s) (6500 89%) 3.4277228908033557\n",
            "2021-06-10 13:32:22,871 - 2m 58s (- 0m 17s) (6600 90%) 3.4898639077125244\n",
            "2021-06-10 13:32:25,282 - 3m 1s (- 0m 15s) (6700 92%) 3.6441816505444145\n",
            "2021-06-10 13:32:27,865 - 3m 3s (- 0m 12s) (6800 93%) 3.430150186602246\n",
            "2021-06-10 13:32:30,576 - 3m 6s (- 0m 9s) (6900 95%) 3.495718755545117\n",
            "2021-06-10 13:32:33,166 - 3m 9s (- 0m 7s) (7000 96%) 3.345914465636338\n",
            "2021-06-10 13:32:35,462 - 3m 11s (- 0m 4s) (7100 97%) 3.4402987271503296\n",
            "2021-06-10 13:32:37,874 - 3m 13s (- 0m 1s) (7200 99%) 3.590503429949306\n",
            "2021-06-10 13:32:39,352 - EPOCH : 1\n",
            "2021-06-10 13:32:39,353 - ------------------------------\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "> [105, 140, 453, 35, 68, 78, 311, 68, 263, 105, 95, 140, 227, 271, 200, 311, 68, 33, 200, 95, 140, 311, 327, 1]\n",
            "= [339, 551, 68, 43, 158, 68, 247, 85, 70, 158, 68, 79, 222, 1]\n",
            "< [607, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 1]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-06-10 13:32:42,027 - 3m 18s (- 236m 20s) (100 1%) 5.471259771509255\n",
            "2021-06-10 13:32:44,647 - 3m 20s (- 118m 3s) (200 2%) 3.415283876193912\n",
            "2021-06-10 13:32:47,266 - 3m 23s (- 78m 36s) (300 4%) 3.525349118737818\n",
            "2021-06-10 13:32:49,930 - 3m 25s (- 58m 52s) (400 5%) 3.521742285855019\n",
            "2021-06-10 13:32:52,746 - 3m 28s (- 47m 2s) (500 6%) 3.352060354859046\n",
            "2021-06-10 13:32:55,584 - 3m 31s (- 39m 8s) (600 8%) 3.478306037649738\n",
            "2021-06-10 13:32:58,178 - 3m 34s (- 33m 27s) (700 9%) 3.541017283548758\n",
            "2021-06-10 13:33:01,013 - 3m 37s (- 29m 12s) (800 11%) 3.5283671136529393\n",
            "2021-06-10 13:33:03,584 - 3m 39s (- 25m 51s) (900 12%) 3.512636212258136\n",
            "2021-06-10 13:33:06,186 - 3m 42s (- 23m 11s) (1000 13%) 3.41699686857367\n",
            "2021-06-10 13:33:08,664 - 3m 44s (- 20m 58s) (1100 15%) 3.5228550274287715\n",
            "2021-06-10 13:33:11,333 - 3m 47s (- 19m 8s) (1200 16%) 3.4130091097454254\n",
            "2021-06-10 13:33:14,255 - 3m 50s (- 17m 35s) (1300 17%) 3.564300820971275\n",
            "2021-06-10 13:33:16,920 - 3m 52s (- 16m 15s) (1400 19%) 3.4114384428220523\n",
            "2021-06-10 13:33:19,861 - 3m 55s (- 15m 5s) (1500 20%) 3.3139320113211728\n",
            "2021-06-10 13:33:22,480 - 3m 58s (- 14m 3s) (1600 22%) 3.537818175790959\n",
            "2021-06-10 13:33:24,970 - 4m 0s (- 13m 8s) (1700 23%) 3.431143707756381\n",
            "2021-06-10 13:33:27,390 - 4m 3s (- 12m 18s) (1800 24%) 3.4041063286482016\n",
            "2021-06-10 13:33:29,901 - 4m 5s (- 11m 33s) (1900 26%) 3.4639796911402785\n",
            "2021-06-10 13:33:32,624 - 4m 8s (- 10m 53s) (2000 27%) 3.531498074544355\n",
            "2021-06-10 13:33:34,992 - 4m 11s (- 10m 16s) (2100 28%) 3.4228659723084287\n",
            "2021-06-10 13:33:37,624 - 4m 13s (- 9m 43s) (2200 30%) 3.5550468798242805\n",
            "2021-06-10 13:33:39,966 - 4m 15s (- 9m 12s) (2300 31%) 3.4881379778842034\n",
            "2021-06-10 13:33:42,790 - 4m 18s (- 8m 44s) (2400 33%) 3.498871970007248\n",
            "2021-06-10 13:33:45,513 - 4m 21s (- 8m 17s) (2500 34%) 3.3534441869479057\n",
            "2021-06-10 13:33:47,889 - 4m 23s (- 7m 53s) (2600 35%) 3.436888603481159\n",
            "2021-06-10 13:33:50,673 - 4m 26s (- 7m 30s) (2700 37%) 3.3042081226106985\n",
            "2021-06-10 13:33:53,312 - 4m 29s (- 7m 9s) (2800 38%) 3.503677879334715\n",
            "2021-06-10 13:33:55,808 - 4m 31s (- 6m 48s) (2900 39%) 3.4761967003047665\n",
            "2021-06-10 13:33:58,573 - 4m 34s (- 6m 29s) (3000 41%) 3.480760606922684\n",
            "2021-06-10 13:34:01,253 - 4m 37s (- 6m 12s) (3100 42%) 3.4682180179318953\n",
            "2021-06-10 13:34:03,752 - 4m 39s (- 5m 54s) (3200 44%) 3.3130391624469473\n",
            "2021-06-10 13:34:06,506 - 4m 42s (- 5m 39s) (3300 45%) 3.4566905163883748\n",
            "2021-06-10 13:34:09,210 - 4m 45s (- 5m 23s) (3400 46%) 3.4419098892272144\n",
            "2021-06-10 13:34:11,853 - 4m 47s (- 5m 9s) (3500 48%) 3.340235571439265\n",
            "2021-06-10 13:34:14,647 - 4m 50s (- 4m 55s) (3600 49%) 3.394054736230147\n",
            "2021-06-10 13:34:17,047 - 4m 53s (- 4m 41s) (3700 50%) 3.5137695088175294\n",
            "2021-06-10 13:34:19,716 - 4m 55s (- 4m 29s) (3800 52%) 3.4858102186665785\n",
            "2021-06-10 13:34:22,417 - 4m 58s (- 4m 17s) (3900 53%) 3.369035621279384\n",
            "2021-06-10 13:34:24,966 - 5m 0s (- 4m 5s) (4000 55%) 3.433564138141016\n",
            "2021-06-10 13:34:27,759 - 5m 3s (- 3m 54s) (4100 56%) 3.456908474465111\n",
            "2021-06-10 13:34:30,254 - 5m 6s (- 3m 43s) (4200 57%) 3.4496967029613885\n",
            "2021-06-10 13:34:33,033 - 5m 9s (- 3m 32s) (4300 59%) 3.4037479557639396\n",
            "2021-06-10 13:34:35,366 - 5m 11s (- 3m 22s) (4400 60%) 3.325460131678799\n",
            "2021-06-10 13:34:38,111 - 5m 14s (- 3m 12s) (4500 61%) 3.2171007813584978\n",
            "2021-06-10 13:34:40,720 - 5m 16s (- 3m 3s) (4600 63%) 3.391487636398375\n",
            "2021-06-10 13:34:43,710 - 5m 19s (- 2m 54s) (4700 64%) 3.34575324544671\n",
            "2021-06-10 13:34:46,646 - 5m 22s (- 2m 45s) (4800 66%) 3.3941331707582174\n",
            "2021-06-10 13:34:49,286 - 5m 25s (- 2m 36s) (4900 67%) 3.3790159985558836\n",
            "2021-06-10 13:34:52,006 - 5m 28s (- 2m 28s) (5000 68%) 3.4010720140179496\n",
            "2021-06-10 13:34:54,554 - 5m 30s (- 2m 20s) (5100 70%) 3.3037129680287007\n",
            "2021-06-10 13:34:56,885 - 5m 32s (- 2m 11s) (5200 71%) 3.3176382141488174\n",
            "2021-06-10 13:34:59,292 - 5m 35s (- 2m 4s) (5300 73%) 3.5201372833586926\n",
            "2021-06-10 13:35:01,822 - 5m 37s (- 1m 56s) (5400 74%) 3.4891368796374227\n",
            "2021-06-10 13:35:04,561 - 5m 40s (- 1m 48s) (5500 75%) 3.362651335564812\n",
            "2021-06-10 13:35:07,103 - 5m 43s (- 1m 41s) (5600 77%) 3.374736482540169\n",
            "2021-06-10 13:35:09,743 - 5m 45s (- 1m 34s) (5700 78%) 3.357043459509863\n",
            "2021-06-10 13:35:12,409 - 5m 48s (- 1m 27s) (5800 79%) 3.338817815893352\n",
            "2021-06-10 13:35:15,202 - 5m 51s (- 1m 20s) (5900 81%) 3.2786229771540665\n",
            "2021-06-10 13:35:17,974 - 5m 54s (- 1m 14s) (6000 82%) 3.412162069156901\n",
            "2021-06-10 13:35:20,519 - 5m 56s (- 1m 7s) (6100 84%) 3.3823672037378447\n",
            "2021-06-10 13:35:22,923 - 5m 58s (- 1m 1s) (6200 85%) 3.3935845633310255\n",
            "2021-06-10 13:35:25,697 - 6m 1s (- 0m 55s) (6300 86%) 3.405641136282442\n",
            "2021-06-10 13:35:28,241 - 6m 4s (- 0m 48s) (6400 88%) 3.39634564473283\n",
            "2021-06-10 13:35:31,101 - 6m 7s (- 0m 42s) (6500 89%) 3.2955111832196833\n",
            "2021-06-10 13:35:33,614 - 6m 9s (- 0m 36s) (6600 90%) 3.277148472746207\n",
            "2021-06-10 13:35:36,073 - 6m 12s (- 0m 31s) (6700 92%) 3.4711974714696083\n",
            "2021-06-10 13:35:38,754 - 6m 14s (- 0m 25s) (6800 93%) 3.2695421040136585\n",
            "2021-06-10 13:35:41,479 - 6m 17s (- 0m 19s) (6900 95%) 3.370046301328602\n",
            "2021-06-10 13:35:44,041 - 6m 20s (- 0m 14s) (7000 96%) 3.1570427772839844\n",
            "2021-06-10 13:35:46,383 - 6m 22s (- 0m 8s) (7100 97%) 3.4236233684837565\n",
            "2021-06-10 13:35:48,777 - 6m 24s (- 0m 3s) (7200 99%) 3.3058113349580793\n",
            "2021-06-10 13:35:50,249 - EPOCH : 2\n",
            "2021-06-10 13:35:50,251 - ------------------------------\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "> [105, 68, 200, 33, 584, 416, 584, 402, 105, 23, 437, 68, 304, 584, 95, 68, 78, 311, 68, 263, 437, 227, 200, 156, 105, 584, 95, 68, 311, 437, 35, 140, 437, 95, 271, 200, 311, 327, 1]\n",
            "= [607, 158, 68, 189, 192, 194, 440, 158, 85, 68, 241, 68, 43, 158, 68, 405, 344, 158, 332, 68, 276, 85, 299, 70, 158, 1]\n",
            "< [607, 158, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 1]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-06-10 13:35:52,974 - 6m 29s (- 464m 12s) (100 1%) 5.447535121776284\n",
            "2021-06-10 13:35:55,517 - 6m 31s (- 230m 21s) (200 2%) 3.355889547952502\n",
            "2021-06-10 13:35:58,102 - 6m 34s (- 152m 23s) (300 4%) 3.298787291685213\n",
            "2021-06-10 13:36:00,834 - 6m 36s (- 113m 26s) (400 5%) 3.474993887013086\n",
            "2021-06-10 13:36:03,802 - 6m 39s (- 90m 5s) (500 6%) 3.1469792909680767\n",
            "2021-06-10 13:36:06,653 - 6m 42s (- 74m 29s) (600 8%) 3.3024967914113947\n",
            "2021-06-10 13:36:09,269 - 6m 45s (- 63m 18s) (700 9%) 3.2463728184016043\n",
            "2021-06-10 13:36:12,084 - 6m 48s (- 54m 55s) (800 11%) 3.3291918467399597\n",
            "2021-06-10 13:36:14,819 - 6m 50s (- 48m 23s) (900 12%) 3.407036843758249\n",
            "2021-06-10 13:36:17,491 - 6m 53s (- 43m 8s) (1000 13%) 3.283404379973552\n",
            "2021-06-10 13:36:19,962 - 6m 55s (- 38m 49s) (1100 15%) 3.244708413638267\n",
            "2021-06-10 13:36:22,645 - 6m 58s (- 35m 14s) (1200 16%) 3.2604530391992057\n",
            "2021-06-10 13:36:25,585 - 7m 1s (- 32m 12s) (1300 17%) 3.4504674904613597\n",
            "2021-06-10 13:36:28,312 - 7m 4s (- 29m 36s) (1400 19%) 3.228492207262758\n",
            "2021-06-10 13:36:31,310 - 7m 7s (- 27m 20s) (1500 20%) 3.2054983933007914\n",
            "2021-06-10 13:36:33,921 - 7m 9s (- 25m 20s) (1600 22%) 3.312682418858978\n",
            "2021-06-10 13:36:36,531 - 7m 12s (- 23m 34s) (1700 23%) 3.247187059986059\n",
            "2021-06-10 13:36:38,963 - 7m 14s (- 21m 59s) (1800 24%) 3.2493804028708912\n",
            "2021-06-10 13:36:41,497 - 7m 17s (- 20m 34s) (1900 26%) 3.1973747184254275\n",
            "2021-06-10 13:36:44,273 - 7m 20s (- 19m 17s) (2000 27%) 3.3248912770435073\n",
            "2021-06-10 13:36:46,726 - 7m 22s (- 18m 7s) (2100 28%) 3.313316232395319\n",
            "2021-06-10 13:36:49,406 - 7m 25s (- 17m 4s) (2200 30%) 3.24455749037847\n",
            "2021-06-10 13:36:51,848 - 7m 27s (- 16m 5s) (2300 31%) 3.4313523134829627\n",
            "2021-06-10 13:36:54,695 - 7m 30s (- 15m 12s) (2400 33%) 3.3588709692577687\n",
            "2021-06-10 13:36:57,420 - 7m 33s (- 14m 23s) (2500 34%) 3.1760042364131813\n",
            "2021-06-10 13:36:59,790 - 7m 35s (- 13m 36s) (2600 35%) 3.2427896959522933\n",
            "2021-06-10 13:37:02,594 - 7m 38s (- 12m 54s) (2700 37%) 3.151541101281806\n",
            "2021-06-10 13:37:05,286 - 7m 41s (- 12m 14s) (2800 38%) 3.319946131841234\n",
            "2021-06-10 13:37:07,779 - 7m 43s (- 11m 37s) (2900 39%) 3.4264734172211813\n",
            "2021-06-10 13:37:10,592 - 7m 46s (- 11m 2s) (3000 41%) 3.2270304722914527\n",
            "2021-06-10 13:37:13,297 - 7m 49s (- 10m 29s) (3100 42%) 3.3823537871667315\n",
            "2021-06-10 13:37:15,935 - 7m 51s (- 9m 58s) (3200 44%) 3.170226392491058\n",
            "2021-06-10 13:37:18,790 - 7m 54s (- 9m 29s) (3300 45%) 3.2676139132265654\n",
            "2021-06-10 13:37:21,647 - 7m 57s (- 9m 2s) (3400 46%) 3.2918611239138538\n",
            "2021-06-10 13:37:24,337 - 8m 0s (- 8m 36s) (3500 48%) 3.2912079716126663\n",
            "2021-06-10 13:37:27,108 - 8m 3s (- 8m 11s) (3600 49%) 3.3087744513070954\n",
            "2021-06-10 13:37:29,551 - 8m 5s (- 7m 47s) (3700 50%) 3.3191231349466235\n",
            "2021-06-10 13:37:32,282 - 8m 8s (- 7m 24s) (3800 52%) 3.3602936389482134\n",
            "2021-06-10 13:37:35,038 - 8m 11s (- 7m 3s) (3900 53%) 3.210931874811463\n",
            "2021-06-10 13:37:37,662 - 8m 13s (- 6m 42s) (4000 55%) 3.2629999833874823\n",
            "2021-06-10 13:37:40,477 - 8m 16s (- 6m 22s) (4100 56%) 3.294026627873249\n",
            "2021-06-10 13:37:43,086 - 8m 19s (- 6m 3s) (4200 57%) 3.1396932760493517\n",
            "2021-06-10 13:37:45,896 - 8m 21s (- 5m 45s) (4300 59%) 3.3050057517818026\n",
            "2021-06-10 13:37:48,241 - 8m 24s (- 5m 27s) (4400 60%) 3.2607520516017443\n",
            "2021-06-10 13:37:51,040 - 8m 27s (- 5m 11s) (4500 61%) 3.188098795915765\n",
            "2021-06-10 13:37:53,701 - 8m 29s (- 4m 54s) (4600 63%) 3.1990814048138554\n",
            "2021-06-10 13:37:56,748 - 8m 32s (- 4m 39s) (4700 64%) 3.1738656699763634\n",
            "2021-06-10 13:37:59,745 - 8m 35s (- 4m 24s) (4800 66%) 3.1769795215685024\n",
            "2021-06-10 13:38:02,402 - 8m 38s (- 4m 9s) (4900 67%) 3.1713539504951744\n",
            "2021-06-10 13:38:05,156 - 8m 41s (- 3m 55s) (5000 68%) 3.29425876720423\n",
            "2021-06-10 13:38:07,764 - 8m 43s (- 3m 41s) (5100 70%) 3.1485795545409614\n",
            "2021-06-10 13:38:10,195 - 8m 46s (- 3m 28s) (5200 71%) 3.1031485256707954\n",
            "2021-06-10 13:38:12,627 - 8m 48s (- 3m 15s) (5300 73%) 3.308819089206643\n",
            "2021-06-10 13:38:15,288 - 8m 51s (- 3m 3s) (5400 74%) 3.393287386839416\n",
            "2021-06-10 13:38:18,091 - 8m 54s (- 2m 50s) (5500 75%) 3.1940014856007157\n",
            "2021-06-10 13:38:20,622 - 8m 56s (- 2m 39s) (5600 77%) 3.172102097989922\n",
            "2021-06-10 13:38:23,305 - 8m 59s (- 2m 27s) (5700 78%) 3.2927644397007754\n",
            "2021-06-10 13:38:26,007 - 9m 2s (- 2m 16s) (5800 79%) 3.202615007281046\n",
            "2021-06-10 13:38:28,922 - 9m 4s (- 2m 5s) (5900 81%) 3.1344745230540707\n",
            "2021-06-10 13:38:31,751 - 9m 7s (- 1m 55s) (6000 82%) 3.2024407080618293\n",
            "2021-06-10 13:38:34,328 - 9m 10s (- 1m 44s) (6100 84%) 3.221259620590168\n",
            "2021-06-10 13:38:36,729 - 9m 12s (- 1m 34s) (6200 85%) 3.3304134359050828\n",
            "2021-06-10 13:38:39,532 - 9m 15s (- 1m 24s) (6300 86%) 3.243157135460458\n",
            "2021-06-10 13:38:42,093 - 9m 18s (- 1m 14s) (6400 88%) 3.272458123812719\n",
            "2021-06-10 13:38:44,991 - 9m 21s (- 1m 5s) (6500 89%) 3.123651170598125\n",
            "2021-06-10 13:38:47,558 - 9m 23s (- 0m 56s) (6600 90%) 3.141731838513447\n",
            "2021-06-10 13:38:50,048 - 9m 26s (- 0m 47s) (6700 92%) 3.31461749724828\n",
            "2021-06-10 13:38:52,789 - 9m 28s (- 0m 38s) (6800 93%) 3.1524519585601722\n",
            "2021-06-10 13:38:55,536 - 9m 31s (- 0m 29s) (6900 95%) 3.1946732205867785\n",
            "2021-06-10 13:38:58,290 - 9m 34s (- 0m 21s) (7000 96%) 3.1336302745259452\n",
            "2021-06-10 13:39:00,678 - 9m 36s (- 0m 12s) (7100 97%) 3.259861472457805\n",
            "2021-06-10 13:39:03,145 - 9m 39s (- 0m 4s) (7200 99%) 3.212204642697692\n",
            "2021-06-10 13:39:04,634 - EPOCH : 3\n",
            "2021-06-10 13:39:04,636 - ------------------------------\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "> [227, 437, 416, 416, 584, 327, 68, 105, 453, 271, 68, 416, 105, 619, 437, 68, 140, 584, 68, 35, 33, 437, 200, 619, 68, 140, 584, 68, 228, 200, 78, 437, 35, 327, 1]\n",
            "= [231, 51, 86, 68, 607, 339, 68, 550, 501, 68, 397, 68, 85, 350, 68, 397, 68, 485, 479, 85, 1]\n",
            "< [607, 158, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 1]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-06-10 13:39:07,373 - 9m 43s (- 696m 11s) (100 1%) 5.297545298936719\n",
            "2021-06-10 13:39:09,984 - 9m 46s (- 344m 46s) (200 2%) 3.1906059938788025\n",
            "2021-06-10 13:39:12,644 - 9m 48s (- 227m 37s) (300 4%) 3.265702498615951\n",
            "2021-06-10 13:39:15,367 - 9m 51s (- 169m 2s) (400 5%) 3.312832940858676\n",
            "2021-06-10 13:39:18,283 - 9m 54s (- 133m 55s) (500 6%) 3.024180177507055\n",
            "2021-06-10 13:39:21,136 - 9m 57s (- 110m 28s) (600 8%) 3.2312658711593083\n",
            "2021-06-10 13:39:23,785 - 9m 59s (- 93m 41s) (700 9%) 3.1261055415591703\n",
            "2021-06-10 13:39:26,653 - 10m 2s (- 81m 6s) (800 11%) 3.3670353687751735\n",
            "2021-06-10 13:39:29,304 - 10m 5s (- 71m 17s) (900 12%) 3.251710391300957\n",
            "2021-06-10 13:39:31,982 - 10m 8s (- 63m 26s) (1000 13%) 3.161601841158549\n",
            "2021-06-10 13:39:34,444 - 10m 10s (- 56m 58s) (1100 15%) 3.0641651505158\n",
            "2021-06-10 13:39:37,129 - 10m 13s (- 51m 36s) (1200 16%) 3.1684034463904966\n",
            "2021-06-10 13:39:40,066 - 10m 16s (- 47m 4s) (1300 17%) 3.2513974586692336\n",
            "2021-06-10 13:39:42,824 - 10m 18s (- 43m 10s) (1400 19%) 3.1576951308932864\n",
            "2021-06-10 13:39:45,836 - 10m 21s (- 39m 47s) (1500 20%) 3.127911769240269\n",
            "2021-06-10 13:39:48,468 - 10m 24s (- 36m 49s) (1600 22%) 3.193821471115159\n",
            "2021-06-10 13:39:51,056 - 10m 27s (- 34m 10s) (1700 23%) 3.1259245923259487\n",
            "2021-06-10 13:39:53,500 - 10m 29s (- 31m 49s) (1800 24%) 3.054998532960746\n",
            "2021-06-10 13:39:56,035 - 10m 32s (- 29m 43s) (1900 26%) 3.1744137154366516\n",
            "2021-06-10 13:39:58,814 - 10m 34s (- 27m 49s) (2000 27%) 3.1741043974098715\n",
            "2021-06-10 13:40:01,230 - 10m 37s (- 26m 5s) (2100 28%) 3.176885839999678\n",
            "2021-06-10 13:40:03,971 - 10m 39s (- 24m 31s) (2200 30%) 3.244168237759593\n",
            "2021-06-10 13:40:06,392 - 10m 42s (- 23m 5s) (2300 31%) 3.2613557519835807\n",
            "2021-06-10 13:40:09,289 - 10m 45s (- 21m 46s) (2400 33%) 3.217464945828443\n",
            "2021-06-10 13:40:12,077 - 10m 48s (- 20m 33s) (2500 34%) 3.0960355437202973\n",
            "2021-06-10 13:40:14,513 - 10m 50s (- 19m 25s) (2600 35%) 3.025708897619265\n",
            "2021-06-10 13:40:17,322 - 10m 53s (- 18m 23s) (2700 37%) 3.0558298006273623\n",
            "2021-06-10 13:40:19,987 - 10m 56s (- 17m 24s) (2800 38%) 3.195072383036954\n",
            "2021-06-10 13:40:22,491 - 10m 58s (- 16m 30s) (2900 39%) 3.1854025856540784\n",
            "2021-06-10 13:40:25,262 - 11m 1s (- 15m 39s) (3000 41%) 3.1776534646886576\n",
            "2021-06-10 13:40:27,966 - 11m 3s (- 14m 51s) (3100 42%) 3.190128847063083\n",
            "2021-06-10 13:40:30,557 - 11m 6s (- 14m 5s) (3200 44%) 3.0223962886312785\n",
            "2021-06-10 13:40:33,375 - 11m 9s (- 13m 23s) (3300 45%) 3.286828457101174\n",
            "2021-06-10 13:40:36,114 - 11m 12s (- 12m 43s) (3400 46%) 3.064935521247554\n",
            "2021-06-10 13:40:38,859 - 11m 14s (- 12m 5s) (3500 48%) 3.202480184395825\n",
            "2021-06-10 13:40:41,645 - 11m 17s (- 11m 28s) (3600 49%) 3.1532385782718086\n",
            "2021-06-10 13:40:44,087 - 11m 20s (- 10m 54s) (3700 50%) 3.215763555051796\n",
            "2021-06-10 13:40:46,803 - 11m 22s (- 10m 21s) (3800 52%) 3.232471715868375\n",
            "2021-06-10 13:40:49,525 - 11m 25s (- 9m 50s) (3900 53%) 3.0946472553944027\n",
            "2021-06-10 13:40:52,123 - 11m 28s (- 9m 20s) (4000 55%) 3.1834724745662437\n",
            "2021-06-10 13:40:54,960 - 11m 30s (- 8m 52s) (4100 56%) 3.082986881297032\n",
            "2021-06-10 13:40:57,558 - 11m 33s (- 8m 25s) (4200 57%) 3.0657719635761804\n",
            "2021-06-10 13:41:00,376 - 11m 36s (- 7m 59s) (4300 59%) 3.2423151878405996\n",
            "2021-06-10 13:41:02,702 - 11m 38s (- 7m 34s) (4400 60%) 3.1293248916957475\n",
            "2021-06-10 13:41:05,512 - 11m 41s (- 7m 10s) (4500 61%) 3.064407755109804\n",
            "2021-06-10 13:41:08,162 - 11m 44s (- 6m 47s) (4600 63%) 3.192507690227024\n",
            "2021-06-10 13:41:11,201 - 11m 47s (- 6m 25s) (4700 64%) 3.0114017407908613\n",
            "2021-06-10 13:41:14,227 - 11m 50s (- 6m 4s) (4800 66%) 3.102061461214559\n",
            "2021-06-10 13:41:16,955 - 11m 52s (- 5m 43s) (4900 67%) 3.0982433974362062\n",
            "2021-06-10 13:41:19,753 - 11m 55s (- 5m 23s) (5000 68%) 3.038697645223033\n",
            "2021-06-10 13:41:22,340 - 11m 58s (- 5m 4s) (5100 70%) 3.0452414512442476\n",
            "2021-06-10 13:41:24,714 - 12m 0s (- 4m 45s) (5200 71%) 3.041738051869192\n",
            "2021-06-10 13:41:27,162 - 12m 3s (- 4m 27s) (5300 73%) 3.2209633636259842\n",
            "2021-06-10 13:41:29,726 - 12m 5s (- 4m 9s) (5400 74%) 3.214255379267287\n",
            "2021-06-10 13:41:32,540 - 12m 8s (- 3m 53s) (5500 75%) 3.1581078505809383\n",
            "2021-06-10 13:41:35,097 - 12m 11s (- 3m 36s) (5600 77%) 3.0366463666442503\n",
            "2021-06-10 13:41:37,766 - 12m 13s (- 3m 20s) (5700 78%) 3.1661308010569122\n",
            "2021-06-10 13:41:40,440 - 12m 16s (- 3m 5s) (5800 79%) 3.0239505177104773\n",
            "2021-06-10 13:41:43,338 - 12m 19s (- 2m 50s) (5900 81%) 3.0228113068037072\n",
            "2021-06-10 13:41:46,156 - 12m 22s (- 2m 35s) (6000 82%) 3.1756003025477066\n",
            "2021-06-10 13:41:48,757 - 12m 24s (- 2m 21s) (6100 84%) 3.16058684775941\n",
            "2021-06-10 13:41:51,202 - 12m 27s (- 2m 7s) (6200 85%) 3.2809077019517203\n",
            "2021-06-10 13:41:53,996 - 12m 30s (- 1m 54s) (6300 86%) 3.1998467424011\n",
            "2021-06-10 13:41:56,591 - 12m 32s (- 1m 41s) (6400 88%) 3.085596698343176\n",
            "2021-06-10 13:41:59,492 - 12m 35s (- 1m 28s) (6500 89%) 3.0334050108072064\n",
            "2021-06-10 13:42:02,044 - 12m 38s (- 1m 15s) (6600 90%) 2.988673711112586\n",
            "2021-06-10 13:42:04,508 - 12m 40s (- 1m 3s) (6700 92%) 3.1296394976285393\n",
            "2021-06-10 13:42:07,218 - 12m 43s (- 0m 51s) (6800 93%) 2.965255885802545\n",
            "2021-06-10 13:42:10,048 - 12m 46s (- 0m 39s) (6900 95%) 3.2248272332187464\n",
            "2021-06-10 13:42:12,703 - 12m 48s (- 0m 28s) (7000 96%) 2.9702261020352534\n",
            "2021-06-10 13:42:15,142 - 12m 51s (- 0m 17s) (7100 97%) 3.1819129716832255\n",
            "2021-06-10 13:42:17,569 - 12m 53s (- 0m 6s) (7200 99%) 3.0567388817783323\n",
            "2021-06-10 13:42:19,052 - EPOCH : 4\n",
            "2021-06-10 13:42:19,054 - ------------------------------\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "> [200, 157, 584, 140, 227, 437, 95, 68, 95, 584, 342, 157, 271, 1]\n",
            "= [189, 426, 569, 68, 550, 487, 149, 1]\n",
            "< [19, 85, 68, 158, 108, 68, 1]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-06-10 13:42:21,787 - 12m 57s (- 928m 11s) (100 1%) 4.985502394152297\n",
            "2021-06-10 13:42:24,364 - 13m 0s (- 459m 7s) (200 2%) 3.0537282870969373\n",
            "2021-06-10 13:42:27,001 - 13m 3s (- 302m 46s) (300 4%) 3.0659047191043807\n",
            "2021-06-10 13:42:29,736 - 13m 5s (- 224m 35s) (400 5%) 3.1996901836460507\n",
            "2021-06-10 13:42:32,597 - 13m 8s (- 177m 42s) (500 6%) 2.8695587208287647\n",
            "2021-06-10 13:42:35,422 - 13m 11s (- 146m 25s) (600 8%) 3.0209697140711755\n",
            "2021-06-10 13:42:38,081 - 13m 14s (- 124m 1s) (700 9%) 3.0326447909449454\n",
            "2021-06-10 13:42:40,956 - 13m 16s (- 107m 15s) (800 11%) 3.1645219248675844\n",
            "2021-06-10 13:42:43,618 - 13m 19s (- 94m 10s) (900 12%) 3.1713654063463377\n",
            "2021-06-10 13:42:46,269 - 13m 22s (- 83m 42s) (1000 13%) 2.988399152379429\n",
            "2021-06-10 13:42:48,801 - 13m 24s (- 75m 7s) (1100 15%) 2.974581612796801\n",
            "2021-06-10 13:42:51,516 - 13m 27s (- 67m 58s) (1200 16%) 2.9737357684403474\n",
            "2021-06-10 13:42:54,446 - 13m 30s (- 61m 55s) (1300 17%) 3.1223812300338216\n",
            "2021-06-10 13:42:57,200 - 13m 33s (- 56m 43s) (1400 19%) 3.023736534106813\n",
            "2021-06-10 13:43:00,227 - 13m 36s (- 52m 14s) (1500 20%) 2.9908064841447963\n",
            "2021-06-10 13:43:02,847 - 13m 38s (- 48m 16s) (1600 22%) 3.0849407911548536\n",
            "2021-06-10 13:43:05,447 - 13m 41s (- 44m 46s) (1700 23%) 3.0143869302663346\n",
            "2021-06-10 13:43:07,903 - 13m 43s (- 41m 39s) (1800 24%) 2.94700553876503\n",
            "2021-06-10 13:43:10,479 - 13m 46s (- 38m 51s) (1900 26%) 3.066809479763955\n",
            "2021-06-10 13:43:13,252 - 13m 49s (- 36m 21s) (2000 27%) 3.1597468979682786\n",
            "2021-06-10 13:43:15,719 - 13m 51s (- 34m 3s) (2100 28%) 3.0871409968383836\n",
            "2021-06-10 13:43:18,429 - 13m 54s (- 31m 59s) (2200 30%) 3.1925341012218693\n",
            "2021-06-10 13:43:20,871 - 13m 56s (- 30m 4s) (2300 31%) 3.1320176093365535\n",
            "2021-06-10 13:43:23,738 - 13m 59s (- 28m 20s) (2400 33%) 3.106526979367238\n",
            "2021-06-10 13:43:26,480 - 14m 2s (- 26m 44s) (2500 34%) 2.9263495603524037\n",
            "2021-06-10 13:43:28,863 - 14m 4s (- 25m 14s) (2600 35%) 3.0152626641542635\n",
            "2021-06-10 13:43:31,771 - 14m 7s (- 23m 51s) (2700 37%) 3.001795328981069\n",
            "2021-06-10 13:43:34,460 - 14m 10s (- 22m 34s) (2800 38%) 3.14248387660716\n",
            "2021-06-10 13:43:36,972 - 14m 12s (- 21m 22s) (2900 39%) 3.109920710831211\n",
            "2021-06-10 13:43:39,796 - 14m 15s (- 20m 15s) (3000 41%) 2.978972328429344\n",
            "2021-06-10 13:43:42,479 - 14m 18s (- 19m 12s) (3100 42%) 3.0930468348597837\n",
            "2021-06-10 13:43:45,049 - 14m 21s (- 18m 12s) (3200 44%) 2.9630789047737927\n",
            "2021-06-10 13:43:47,890 - 14m 23s (- 17m 16s) (3300 45%) 2.959914093203413\n",
            "2021-06-10 13:43:50,655 - 14m 26s (- 16m 23s) (3400 46%) 3.05241747199032\n",
            "2021-06-10 13:43:53,395 - 14m 29s (- 15m 34s) (3500 48%) 3.0381027767572033\n",
            "2021-06-10 13:43:56,217 - 14m 32s (- 14m 46s) (3600 49%) 2.968387599833154\n",
            "2021-06-10 13:43:58,730 - 14m 34s (- 14m 1s) (3700 50%) 3.0495458100212254\n",
            "2021-06-10 13:44:01,427 - 14m 37s (- 13m 18s) (3800 52%) 3.1054537372268682\n",
            "2021-06-10 13:44:04,175 - 14m 40s (- 12m 38s) (3900 53%) 3.0303942974733498\n",
            "2021-06-10 13:44:06,764 - 14m 42s (- 11m 59s) (4000 55%) 3.0286529962331796\n",
            "2021-06-10 13:44:09,602 - 14m 45s (- 11m 22s) (4100 56%) 3.0194945444816086\n",
            "2021-06-10 13:44:12,163 - 14m 48s (- 10m 47s) (4200 57%) 2.926075094536566\n",
            "2021-06-10 13:44:14,989 - 14m 51s (- 10m 13s) (4300 59%) 2.9870906294883257\n",
            "2021-06-10 13:44:17,321 - 14m 53s (- 9m 40s) (4400 60%) 2.9422252444556123\n",
            "2021-06-10 13:44:20,038 - 14m 56s (- 9m 9s) (4500 61%) 2.9042173480005515\n",
            "2021-06-10 13:44:22,678 - 14m 58s (- 8m 39s) (4600 63%) 3.045186834552152\n",
            "2021-06-10 13:44:25,686 - 15m 1s (- 8m 11s) (4700 64%) 2.98034847026201\n",
            "2021-06-10 13:44:28,725 - 15m 4s (- 7m 43s) (4800 66%) 2.991866847972688\n",
            "2021-06-10 13:44:31,425 - 15m 7s (- 7m 17s) (4900 67%) 2.8632644109872456\n",
            "2021-06-10 13:44:34,184 - 15m 10s (- 6m 51s) (5000 68%) 2.9567910696986166\n",
            "2021-06-10 13:44:36,776 - 15m 12s (- 6m 26s) (5100 70%) 2.945600024514401\n",
            "2021-06-10 13:44:39,137 - 15m 15s (- 6m 2s) (5200 71%) 2.967496865479147\n",
            "2021-06-10 13:44:41,610 - 15m 17s (- 5m 39s) (5300 73%) 3.0729598458785587\n",
            "2021-06-10 13:44:44,181 - 15m 20s (- 5m 16s) (5400 74%) 3.0254158046079764\n",
            "2021-06-10 13:44:46,988 - 15m 23s (- 4m 55s) (5500 75%) 2.972868865664421\n",
            "2021-06-10 13:44:49,584 - 15m 25s (- 4m 34s) (5600 77%) 2.957017330505\n",
            "2021-06-10 13:44:52,265 - 15m 28s (- 4m 14s) (5700 78%) 2.9821003377477\n",
            "2021-06-10 13:44:54,977 - 15m 31s (- 3m 54s) (5800 79%) 2.8394056545897413\n",
            "2021-06-10 13:44:57,809 - 15m 33s (- 3m 35s) (5900 81%) 2.891719280398365\n",
            "2021-06-10 13:45:00,664 - 15m 36s (- 3m 16s) (6000 82%) 3.070152857471279\n",
            "2021-06-10 13:45:03,262 - 15m 39s (- 2m 58s) (6100 84%) 2.960594948473688\n",
            "2021-06-10 13:45:05,694 - 15m 41s (- 2m 41s) (6200 85%) 3.079209510154982\n",
            "2021-06-10 13:45:08,519 - 15m 44s (- 2m 23s) (6300 86%) 3.1381490232312914\n",
            "2021-06-10 13:45:11,096 - 15m 47s (- 2m 7s) (6400 88%) 2.986120527135165\n",
            "2021-06-10 13:45:14,063 - 15m 50s (- 1m 51s) (6500 89%) 2.9067602222582836\n",
            "2021-06-10 13:45:16,683 - 15m 52s (- 1m 35s) (6600 90%) 2.814657556397876\n",
            "2021-06-10 13:45:19,149 - 15m 55s (- 1m 19s) (6700 92%) 3.0922539952294357\n",
            "2021-06-10 13:45:21,879 - 15m 57s (- 1m 4s) (6800 93%) 2.8450661865250457\n",
            "2021-06-10 13:45:24,697 - 16m 0s (- 0m 50s) (6900 95%) 3.086438074369849\n",
            "2021-06-10 13:45:27,373 - 16m 3s (- 0m 35s) (7000 96%) 2.917532246925652\n",
            "2021-06-10 13:45:29,767 - 16m 5s (- 0m 21s) (7100 97%) 2.965725954070351\n",
            "2021-06-10 13:45:32,269 - 16m 8s (- 0m 8s) (7200 99%) 2.9441628273026765\n",
            "2021-06-10 13:45:33,837 - EPOCH : 5\n",
            "2021-06-10 13:45:33,839 - ------------------------------\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "> [29, 227, 584, 68, 271, 584, 68, 105, 68, 52, 584, 157, 140, 200, 52, 140, 68, 105, 304, 68, 140, 227, 437, 95, 437, 453, 35, 68, 200, 68, 33, 95, 584, 263, 416, 437, 78, 68, 29, 105, 140, 227, 68, 140, 227, 437, 68, 227, 584, 342, 35, 437, 113, 1]\n",
            "= [495, 68, 370, 68, 607, 158, 68, 295, 345, 68, 158, 240, 68, 70, 189, 108, 68, 189, 68, 240, 550, 213, 223, 68, 196, 68, 569, 68, 261, 86, 85, 1]\n",
            "< [370, 68, 5, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 1]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-06-10 13:45:36,608 - 16m 12s (- 1160m 40s) (100 1%) 4.904277888964552\n",
            "2021-06-10 13:45:39,186 - 16m 15s (- 573m 45s) (200 2%) 2.924596631891684\n",
            "2021-06-10 13:45:41,910 - 16m 17s (- 378m 8s) (300 4%) 2.9730643491790247\n",
            "2021-06-10 13:45:44,663 - 16m 20s (- 280m 18s) (400 5%) 2.9850855453774243\n",
            "2021-06-10 13:45:47,540 - 16m 23s (- 221m 37s) (500 6%) 2.8100088066639906\n",
            "2021-06-10 13:45:50,392 - 16m 26s (- 182m 29s) (600 8%) 2.92471585722289\n",
            "2021-06-10 13:45:53,085 - 16m 29s (- 154m 29s) (700 9%) 2.931348571840347\n",
            "2021-06-10 13:45:55,965 - 16m 31s (- 133m 30s) (800 11%) 3.0007772064692713\n",
            "2021-06-10 13:45:58,637 - 16m 34s (- 117m 8s) (900 12%) 3.0610493998482378\n",
            "2021-06-10 13:46:01,338 - 16m 37s (- 104m 3s) (1000 13%) 2.9080537878481567\n",
            "2021-06-10 13:46:03,838 - 16m 39s (- 93m 19s) (1100 15%) 2.8727113994795457\n",
            "2021-06-10 13:46:06,590 - 16m 42s (- 84m 23s) (1200 16%) 2.8891244657550583\n",
            "2021-06-10 13:46:09,552 - 16m 45s (- 76m 50s) (1300 17%) 2.950835604215806\n",
            "2021-06-10 13:46:12,332 - 16m 48s (- 70m 20s) (1400 19%) 2.979649796365645\n",
            "2021-06-10 13:46:15,423 - 16m 51s (- 64m 43s) (1500 20%) 2.760267034017284\n",
            "2021-06-10 13:46:18,035 - 16m 54s (- 59m 47s) (1600 22%) 2.923541051245743\n",
            "2021-06-10 13:46:20,638 - 16m 56s (- 55m 25s) (1700 23%) 2.83827144272798\n",
            "2021-06-10 13:46:23,075 - 16m 59s (- 51m 31s) (1800 24%) 2.760653948398504\n",
            "2021-06-10 13:46:25,655 - 17m 1s (- 48m 2s) (1900 26%) 2.8505354132173557\n",
            "2021-06-10 13:46:28,435 - 17m 4s (- 44m 54s) (2000 27%) 2.943698436659031\n",
            "2021-06-10 13:46:30,892 - 17m 6s (- 42m 3s) (2100 28%) 3.0584142205143663\n",
            "2021-06-10 13:46:33,606 - 17m 9s (- 39m 28s) (2200 30%) 2.9352740015263334\n",
            "2021-06-10 13:46:36,043 - 17m 12s (- 37m 5s) (2300 31%) 2.981589314545655\n",
            "2021-06-10 13:46:38,913 - 17m 14s (- 34m 55s) (2400 33%) 2.865019021774683\n",
            "2021-06-10 13:46:41,738 - 17m 17s (- 32m 55s) (2500 34%) 2.8335355018983925\n",
            "2021-06-10 13:46:44,131 - 17m 20s (- 31m 4s) (2600 35%) 2.764128515569866\n",
            "2021-06-10 13:46:46,941 - 17m 22s (- 29m 21s) (2700 37%) 2.8816932371975397\n",
            "2021-06-10 13:46:49,642 - 17m 25s (- 27m 45s) (2800 38%) 2.852430809695936\n",
            "2021-06-10 13:46:52,169 - 17m 28s (- 26m 15s) (2900 39%) 2.944931115057887\n",
            "2021-06-10 13:46:55,012 - 17m 31s (- 24m 52s) (3000 41%) 2.8115707823666996\n",
            "2021-06-10 13:46:57,716 - 17m 33s (- 23m 34s) (3100 42%) 2.8856853717538\n",
            "2021-06-10 13:47:00,281 - 17m 36s (- 22m 20s) (3200 44%) 2.7739218567610693\n",
            "2021-06-10 13:47:03,111 - 17m 39s (- 21m 10s) (3300 45%) 2.8190995845742703\n",
            "2021-06-10 13:47:05,866 - 17m 41s (- 20m 5s) (3400 46%) 2.7995062259088197\n",
            "2021-06-10 13:47:08,610 - 17m 44s (- 19m 3s) (3500 48%) 2.829654143939996\n",
            "2021-06-10 13:47:11,426 - 17m 47s (- 18m 5s) (3600 49%) 2.8137924450314222\n",
            "2021-06-10 13:47:13,923 - 17m 49s (- 17m 9s) (3700 50%) 2.9884271518586165\n",
            "2021-06-10 13:47:16,695 - 17m 52s (- 16m 16s) (3800 52%) 2.8684610667335995\n",
            "2021-06-10 13:47:19,442 - 17m 55s (- 15m 26s) (3900 53%) 2.797090680340025\n",
            "2021-06-10 13:47:22,090 - 17m 58s (- 14m 38s) (4000 55%) 2.797330029004148\n",
            "2021-06-10 13:47:24,956 - 18m 0s (- 13m 53s) (4100 56%) 2.882983999363867\n",
            "2021-06-10 13:47:27,531 - 18m 3s (- 13m 9s) (4200 57%) 2.812295403216743\n",
            "2021-06-10 13:47:30,332 - 18m 6s (- 12m 27s) (4300 59%) 2.8004387101193196\n",
            "2021-06-10 13:47:32,661 - 18m 8s (- 11m 47s) (4400 60%) 2.8695678762339907\n",
            "2021-06-10 13:47:35,427 - 18m 11s (- 11m 9s) (4500 61%) 2.755399440168644\n",
            "2021-06-10 13:47:38,079 - 18m 14s (- 10m 32s) (4600 63%) 2.8108777450079656\n",
            "2021-06-10 13:47:41,103 - 18m 17s (- 9m 57s) (4700 64%) 2.8050598229604096\n",
            "2021-06-10 13:47:44,109 - 18m 20s (- 9m 23s) (4800 66%) 2.766119723159326\n",
            "2021-06-10 13:47:46,896 - 18m 22s (- 8m 51s) (4900 67%) 2.7333346572687343\n",
            "2021-06-10 13:47:49,650 - 18m 25s (- 8m 19s) (5000 68%) 2.779119087551651\n",
            "2021-06-10 13:47:52,275 - 18m 28s (- 7m 49s) (5100 70%) 2.7051263201687563\n",
            "2021-06-10 13:47:54,608 - 18m 30s (- 7m 19s) (5200 71%) 2.822301428340099\n",
            "2021-06-10 13:47:57,070 - 18m 33s (- 6m 51s) (5300 73%) 2.881597194261559\n",
            "2021-06-10 13:47:59,679 - 18m 35s (- 6m 24s) (5400 74%) 2.891343498557039\n",
            "2021-06-10 13:48:02,515 - 18m 38s (- 5m 57s) (5500 75%) 2.853883070804822\n",
            "2021-06-10 13:48:05,092 - 18m 41s (- 5m 32s) (5600 77%) 2.8133589822732072\n",
            "2021-06-10 13:48:07,805 - 18m 43s (- 5m 7s) (5700 78%) 2.875444030666718\n",
            "2021-06-10 13:48:10,537 - 18m 46s (- 4m 43s) (5800 79%) 2.7657250443610466\n",
            "2021-06-10 13:48:13,436 - 18m 49s (- 4m 20s) (5900 81%) 2.8265917469884276\n",
            "2021-06-10 13:48:16,319 - 18m 52s (- 3m 57s) (6000 82%) 2.848483832080126\n",
            "2021-06-10 13:48:18,941 - 18m 54s (- 3m 35s) (6100 84%) 2.8564080363381787\n",
            "2021-06-10 13:48:21,392 - 18m 57s (- 3m 14s) (6200 85%) 2.987174213192605\n",
            "2021-06-10 13:48:24,295 - 19m 0s (- 2m 53s) (6300 86%) 2.9237955001391494\n",
            "2021-06-10 13:48:26,941 - 19m 2s (- 2m 33s) (6400 88%) 2.854850296585803\n",
            "2021-06-10 13:48:29,885 - 19m 5s (- 2m 13s) (6500 89%) 2.7438649418027556\n",
            "2021-06-10 13:48:32,430 - 19m 8s (- 1m 54s) (6600 90%) 2.651995249601719\n",
            "2021-06-10 13:48:34,930 - 19m 10s (- 1m 36s) (6700 92%) 2.865873944975756\n",
            "2021-06-10 13:48:37,644 - 19m 13s (- 1m 18s) (6800 93%) 2.615607503384552\n",
            "2021-06-10 13:48:40,461 - 19m 16s (- 1m 0s) (6900 95%) 2.8136241673320708\n",
            "2021-06-10 13:48:43,158 - 19m 19s (- 0m 43s) (7000 96%) 2.70926464656006\n",
            "2021-06-10 13:48:45,596 - 19m 21s (- 0m 26s) (7100 97%) 2.880581178648006\n",
            "2021-06-10 13:48:48,078 - 19m 24s (- 0m 9s) (7200 99%) 2.8117329396390303\n",
            "2021-06-10 13:48:49,601 - EPOCH : 6\n",
            "2021-06-10 13:48:49,603 - ------------------------------\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "> [35, 140, 200, 311, 68, 35, 140, 95, 584, 157, 402, 1]\n",
            "= [85, 347, 158, 68, 85, 359, 124, 1]\n",
            "< [85, 85, 359, 68, 85, 1]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-06-10 13:48:52,390 - 19m 28s (- 1394m 18s) (100 1%) 4.641579199632276\n",
            "2021-06-10 13:48:55,043 - 19m 31s (- 688m 58s) (200 2%) 2.7283837843177463\n",
            "2021-06-10 13:48:57,736 - 19m 33s (- 453m 51s) (300 4%) 2.749779735887012\n",
            "2021-06-10 13:49:00,473 - 19m 36s (- 336m 16s) (400 5%) 2.886338337257084\n",
            "2021-06-10 13:49:03,369 - 19m 39s (- 265m 45s) (500 6%) 2.625537942197223\n",
            "2021-06-10 13:49:06,247 - 19m 42s (- 218m 43s) (600 8%) 2.6785245697435887\n",
            "2021-06-10 13:49:08,915 - 19m 44s (- 185m 4s) (700 9%) 2.728118732786479\n",
            "2021-06-10 13:49:11,814 - 19m 47s (- 159m 51s) (800 11%) 2.8770938339403807\n",
            "2021-06-10 13:49:14,477 - 19m 50s (- 140m 12s) (900 12%) 2.877425813178862\n",
            "2021-06-10 13:49:17,202 - 19m 53s (- 124m 29s) (1000 13%) 2.690435743011766\n",
            "2021-06-10 13:49:19,700 - 19m 55s (- 111m 36s) (1100 15%) 2.6207111751711034\n",
            "2021-06-10 13:49:22,391 - 19m 58s (- 100m 52s) (1200 16%) 2.673413357199875\n",
            "2021-06-10 13:49:25,381 - 20m 1s (- 91m 47s) (1300 17%) 2.801453329989944\n",
            "2021-06-10 13:49:28,176 - 20m 4s (- 84m 0s) (1400 19%) 2.6676507169548076\n",
            "2021-06-10 13:49:31,205 - 20m 7s (- 77m 15s) (1500 20%) 2.6911832320608653\n",
            "2021-06-10 13:49:33,823 - 20m 9s (- 71m 19s) (1600 22%) 2.7162138909606215\n",
            "2021-06-10 13:49:36,417 - 20m 12s (- 66m 5s) (1700 23%) 2.638465982568036\n",
            "2021-06-10 13:49:38,875 - 20m 14s (- 61m 25s) (1800 24%) 2.534397988909216\n",
            "2021-06-10 13:49:41,478 - 20m 17s (- 57m 14s) (1900 26%) 2.777848955229976\n",
            "2021-06-10 13:49:44,261 - 20m 20s (- 53m 29s) (2000 27%) 2.735876897564894\n",
            "2021-06-10 13:49:46,714 - 20m 22s (- 50m 4s) (2100 28%) 2.8440906608357825\n",
            "2021-06-10 13:49:49,443 - 20m 25s (- 46m 58s) (2200 30%) 2.7354715376946372\n",
            "2021-06-10 13:49:51,920 - 20m 27s (- 44m 8s) (2300 31%) 2.8466718177156944\n",
            "2021-06-10 13:49:54,818 - 20m 30s (- 41m 32s) (2400 33%) 2.7550502823479786\n",
            "2021-06-10 13:49:57,633 - 20m 33s (- 39m 8s) (2500 34%) 2.5955093583425923\n",
            "2021-06-10 13:50:00,079 - 20m 36s (- 36m 55s) (2600 35%) 2.656593975602157\n",
            "2021-06-10 13:50:02,919 - 20m 38s (- 34m 52s) (2700 37%) 2.5782041549163894\n",
            "2021-06-10 13:50:05,656 - 20m 41s (- 32m 57s) (2800 38%) 2.6868591003627937\n",
            "2021-06-10 13:50:08,203 - 20m 44s (- 31m 10s) (2900 39%) 2.7298024233221216\n",
            "2021-06-10 13:50:11,044 - 20m 47s (- 29m 30s) (3000 41%) 2.605449613089531\n",
            "2021-06-10 13:50:13,741 - 20m 49s (- 27m 57s) (3100 42%) 2.658972775925639\n",
            "2021-06-10 13:50:16,348 - 20m 52s (- 26m 28s) (3200 44%) 2.6059312408820876\n",
            "2021-06-10 13:50:19,162 - 20m 55s (- 25m 6s) (3300 45%) 2.674514750337321\n",
            "2021-06-10 13:50:21,950 - 20m 57s (- 23m 48s) (3400 46%) 2.6190837457146525\n",
            "2021-06-10 13:50:24,719 - 21m 0s (- 22m 34s) (3500 48%) 2.612348670609905\n",
            "2021-06-10 13:50:27,547 - 21m 3s (- 21m 24s) (3600 49%) 2.651868194187998\n",
            "2021-06-10 13:50:30,074 - 21m 6s (- 20m 18s) (3700 50%) 2.7594926955899672\n",
            "2021-06-10 13:50:32,862 - 21m 8s (- 19m 15s) (3800 52%) 2.740497614703074\n",
            "2021-06-10 13:50:35,603 - 21m 11s (- 18m 15s) (3900 53%) 2.5600024568195128\n",
            "2021-06-10 13:50:38,248 - 21m 14s (- 17m 18s) (4000 55%) 2.685292635646757\n",
            "2021-06-10 13:50:41,156 - 21m 17s (- 16m 24s) (4100 56%) 2.65241595038005\n",
            "2021-06-10 13:50:43,767 - 21m 19s (- 15m 32s) (4200 57%) 2.667020349611747\n",
            "2021-06-10 13:50:46,612 - 21m 22s (- 14m 42s) (4300 59%) 2.6370908887241846\n",
            "2021-06-10 13:50:48,952 - 21m 24s (- 13m 55s) (4400 60%) 2.6676982423351863\n",
            "2021-06-10 13:50:51,698 - 21m 27s (- 13m 9s) (4500 61%) 2.6108186934237625\n",
            "2021-06-10 13:50:54,351 - 21m 30s (- 12m 26s) (4600 63%) 2.6105978275866404\n",
            "2021-06-10 13:50:57,425 - 21m 33s (- 11m 44s) (4700 64%) 2.5119446415166258\n",
            "2021-06-10 13:51:00,431 - 21m 36s (- 11m 4s) (4800 66%) 2.653076823148241\n",
            "2021-06-10 13:51:03,201 - 21m 39s (- 10m 25s) (4900 67%) 2.6086135236679877\n",
            "2021-06-10 13:51:05,972 - 21m 41s (- 9m 48s) (5000 68%) 2.654935166271778\n",
            "2021-06-10 13:51:08,562 - 21m 44s (- 9m 12s) (5100 70%) 2.63540634165454\n",
            "2021-06-10 13:51:10,920 - 21m 46s (- 8m 37s) (5200 71%) 2.627758030566473\n",
            "2021-06-10 13:51:13,336 - 21m 49s (- 8m 4s) (5300 73%) 2.71912955207217\n",
            "2021-06-10 13:51:15,897 - 21m 51s (- 7m 31s) (5400 74%) 2.7737221171364994\n",
            "2021-06-10 13:51:18,661 - 21m 54s (- 7m 0s) (5500 75%) 2.6126380777875977\n",
            "2021-06-10 13:51:21,209 - 21m 57s (- 6m 30s) (5600 77%) 2.716471630652123\n",
            "2021-06-10 13:51:23,867 - 21m 59s (- 6m 1s) (5700 78%) 2.699343600654658\n",
            "2021-06-10 13:51:26,569 - 22m 2s (- 5m 32s) (5800 79%) 2.5093795455908428\n",
            "2021-06-10 13:51:29,404 - 22m 5s (- 5m 5s) (5900 81%) 2.582716351072213\n",
            "2021-06-10 13:51:32,185 - 22m 8s (- 4m 38s) (6000 82%) 2.6689755312569146\n",
            "2021-06-10 13:51:34,749 - 22m 10s (- 4m 13s) (6100 84%) 2.6685482126110984\n",
            "2021-06-10 13:51:37,225 - 22m 13s (- 3m 47s) (6200 85%) 2.686703679249627\n",
            "2021-06-10 13:51:40,036 - 22m 16s (- 3m 23s) (6300 86%) 2.7524347453569886\n",
            "2021-06-10 13:51:42,610 - 22m 18s (- 2m 59s) (6400 88%) 2.7560632113854795\n",
            "2021-06-10 13:51:45,519 - 22m 21s (- 2m 36s) (6500 89%) 2.5512261829427754\n",
            "2021-06-10 13:51:48,088 - 22m 24s (- 2m 14s) (6600 90%) 2.6189247110092406\n",
            "2021-06-10 13:51:50,541 - 22m 26s (- 1m 52s) (6700 92%) 2.6524921956488647\n",
            "2021-06-10 13:51:53,219 - 22m 29s (- 1m 31s) (6800 93%) 2.4725575006086995\n",
            "2021-06-10 13:51:56,010 - 22m 32s (- 1m 10s) (6900 95%) 2.5951091598595424\n",
            "2021-06-10 13:51:58,676 - 22m 34s (- 0m 50s) (7000 96%) 2.5551442376584963\n",
            "2021-06-10 13:52:01,038 - 22m 37s (- 0m 30s) (7100 97%) 2.6732741139754483\n",
            "2021-06-10 13:52:03,495 - 22m 39s (- 0m 11s) (7200 99%) 2.5434421815100983\n",
            "2021-06-10 13:52:05,016 - EPOCH : 7\n",
            "2021-06-10 13:52:05,018 - ------------------------------\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "> [35, 342, 95, 437, 327, 68, 29, 584, 342, 416, 271, 68, 311, 584, 342, 68, 416, 105, 619, 437, 68, 140, 584, 68, 33, 200, 311, 68, 105, 157, 68, 105, 157, 35, 140, 200, 416, 416, 78, 437, 157, 140, 35, 68, 584, 95, 68, 105, 157, 68, 304, 342, 416, 416, 113, 1]\n",
            "= [635, 189, 68, 86, 163, 68, 550, 501, 68, 397, 68, 447, 158, 68, 430, 68, 430, 85, 142, 438, 551, 68, 321, 189, 68, 430, 68, 505, 1]\n",
            "< [503, 189, 68, 5, 68, 5, 68, 5, 68, 550, 501, 68, 397, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 1]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-06-10 13:52:07,741 - 22m 43s (- 1627m 25s) (100 1%) 4.338446949441317\n",
            "2021-06-10 13:52:10,391 - 22m 46s (- 803m 54s) (200 2%) 2.5456748374468887\n",
            "2021-06-10 13:52:13,060 - 22m 49s (- 529m 22s) (300 4%) 2.582810416862119\n",
            "2021-06-10 13:52:15,817 - 22m 51s (- 392m 7s) (400 5%) 2.731736132692218\n",
            "2021-06-10 13:52:18,642 - 22m 54s (- 309m 45s) (500 6%) 2.4719812609856784\n",
            "2021-06-10 13:52:21,409 - 22m 57s (- 254m 49s) (600 8%) 2.6014333886353267\n",
            "2021-06-10 13:52:24,036 - 23m 0s (- 215m 33s) (700 9%) 2.539996573550372\n",
            "2021-06-10 13:52:26,894 - 23m 2s (- 186m 7s) (800 11%) 2.6888885698214158\n",
            "2021-06-10 13:52:29,497 - 23m 5s (- 163m 11s) (900 12%) 2.6902720363079555\n",
            "2021-06-10 13:52:32,149 - 23m 8s (- 144m 49s) (1000 13%) 2.54417983324017\n",
            "2021-06-10 13:52:34,621 - 23m 10s (- 129m 47s) (1100 15%) 2.4600487973093492\n",
            "2021-06-10 13:52:37,331 - 23m 13s (- 117m 16s) (1200 16%) 2.4675615906896238\n",
            "2021-06-10 13:52:40,260 - 23m 16s (- 106m 41s) (1300 17%) 2.541020886306253\n",
            "2021-06-10 13:52:43,052 - 23m 19s (- 97m 36s) (1400 19%) 2.581165843310788\n",
            "2021-06-10 13:52:46,027 - 23m 22s (- 89m 43s) (1500 20%) 2.517476841903168\n",
            "2021-06-10 13:52:48,640 - 23m 24s (- 82m 49s) (1600 22%) 2.5419091662577626\n",
            "2021-06-10 13:52:51,205 - 23m 27s (- 76m 42s) (1700 23%) 2.5727071992899173\n",
            "2021-06-10 13:52:53,653 - 23m 29s (- 71m 16s) (1800 24%) 2.33275598009368\n",
            "2021-06-10 13:52:56,193 - 23m 32s (- 66m 23s) (1900 26%) 2.6002043214356063\n",
            "2021-06-10 13:52:58,904 - 23m 34s (- 62m 1s) (2000 27%) 2.508916537535994\n",
            "2021-06-10 13:53:01,334 - 23m 37s (- 58m 2s) (2100 28%) 2.6025253194655784\n",
            "2021-06-10 13:53:04,030 - 23m 40s (- 54m 26s) (2200 30%) 2.507816522590599\n",
            "2021-06-10 13:53:06,471 - 23m 42s (- 51m 7s) (2300 31%) 2.6125492748083214\n",
            "2021-06-10 13:53:09,326 - 23m 45s (- 48m 6s) (2400 33%) 2.5023729407904796\n",
            "2021-06-10 13:53:12,074 - 23m 48s (- 45m 19s) (2500 34%) 2.4471571282470066\n",
            "2021-06-10 13:53:14,471 - 23m 50s (- 42m 43s) (2600 35%) 2.3870611098377315\n",
            "2021-06-10 13:53:17,329 - 23m 53s (- 40m 20s) (2700 37%) 2.470058999182674\n",
            "2021-06-10 13:53:20,145 - 23m 56s (- 38m 7s) (2800 38%) 2.5322342021351614\n",
            "2021-06-10 13:53:22,755 - 23m 58s (- 36m 3s) (2900 39%) 2.632295767306642\n",
            "2021-06-10 13:53:25,665 - 24m 1s (- 34m 7s) (3000 41%) 2.3430755362777207\n",
            "2021-06-10 13:53:28,346 - 24m 4s (- 32m 18s) (3100 42%) 2.4952580734622276\n",
            "2021-06-10 13:53:30,848 - 24m 6s (- 30m 35s) (3200 44%) 2.4392071177713617\n",
            "2021-06-10 13:53:33,657 - 24m 9s (- 28m 59s) (3300 45%) 2.442562912149949\n",
            "2021-06-10 13:53:36,377 - 24m 12s (- 27m 28s) (3400 46%) 2.468237548215409\n",
            "2021-06-10 13:53:39,097 - 24m 15s (- 26m 3s) (3500 48%) 2.530481485402129\n",
            "2021-06-10 13:53:41,906 - 24m 17s (- 24m 42s) (3600 49%) 2.5002772171003103\n",
            "2021-06-10 13:53:44,411 - 24m 20s (- 23m 25s) (3700 50%) 2.641495736795034\n",
            "2021-06-10 13:53:47,199 - 24m 23s (- 22m 12s) (3800 52%) 2.420284179121703\n",
            "2021-06-10 13:53:50,049 - 24m 26s (- 21m 3s) (3900 53%) 2.4414938532502317\n",
            "2021-06-10 13:53:52,695 - 24m 28s (- 19m 57s) (4000 55%) 2.5184002425550647\n",
            "2021-06-10 13:53:55,559 - 24m 31s (- 18m 54s) (4100 56%) 2.489680527351048\n",
            "2021-06-10 13:53:58,179 - 24m 34s (- 17m 54s) (4200 57%) 2.4818160295257297\n",
            "2021-06-10 13:54:01,031 - 24m 37s (- 16m 56s) (4300 59%) 2.421324938470519\n",
            "2021-06-10 13:54:03,381 - 24m 39s (- 16m 1s) (4400 60%) 2.4629520180953524\n",
            "2021-06-10 13:54:06,180 - 24m 42s (- 15m 9s) (4500 61%) 2.444684465748567\n",
            "2021-06-10 13:54:08,849 - 24m 44s (- 14m 18s) (4600 63%) 2.4734959153664504\n",
            "2021-06-10 13:54:11,950 - 24m 47s (- 13m 30s) (4700 64%) 2.358478742787804\n",
            "2021-06-10 13:54:14,993 - 24m 51s (- 12m 44s) (4800 66%) 2.3104510270583267\n",
            "2021-06-10 13:54:17,740 - 24m 53s (- 11m 59s) (4900 67%) 2.3846717365677734\n",
            "2021-06-10 13:54:20,537 - 24m 56s (- 11m 16s) (5000 68%) 2.3772376311935353\n",
            "2021-06-10 13:54:23,244 - 24m 59s (- 10m 34s) (5100 70%) 2.333993566826724\n",
            "2021-06-10 13:54:25,617 - 25m 1s (- 9m 54s) (5200 71%) 2.4475493734308493\n",
            "2021-06-10 13:54:28,073 - 25m 4s (- 9m 16s) (5300 73%) 2.566849510263543\n",
            "2021-06-10 13:54:30,670 - 25m 6s (- 8m 38s) (5400 74%) 2.5279646460518372\n",
            "2021-06-10 13:54:33,510 - 25m 9s (- 8m 3s) (5500 75%) 2.429411117195852\n",
            "2021-06-10 13:54:36,094 - 25m 12s (- 7m 28s) (5600 77%) 2.491995492050682\n",
            "2021-06-10 13:54:38,787 - 25m 14s (- 6m 54s) (5700 78%) 2.51102028996069\n",
            "2021-06-10 13:54:41,512 - 25m 17s (- 6m 22s) (5800 79%) 2.3963523015898365\n",
            "2021-06-10 13:54:44,395 - 25m 20s (- 5m 50s) (5900 81%) 2.3999751757316\n",
            "2021-06-10 13:54:47,227 - 25m 23s (- 5m 19s) (6000 82%) 2.2790905285670466\n",
            "2021-06-10 13:54:49,876 - 25m 25s (- 4m 50s) (6100 84%) 2.494401915341244\n",
            "2021-06-10 13:54:52,346 - 25m 28s (- 4m 21s) (6200 85%) 2.5267570012391287\n",
            "2021-06-10 13:54:55,205 - 25m 31s (- 3m 53s) (6300 86%) 2.4607467887062744\n",
            "2021-06-10 13:54:57,876 - 25m 33s (- 3m 26s) (6400 88%) 2.5826067198045\n",
            "2021-06-10 13:55:00,847 - 25m 36s (- 2m 59s) (6500 89%) 2.217401310894936\n",
            "2021-06-10 13:55:03,445 - 25m 39s (- 2m 33s) (6600 90%) 2.3882167113118435\n",
            "2021-06-10 13:55:05,948 - 25m 41s (- 2m 8s) (6700 92%) 2.4479328979261195\n",
            "2021-06-10 13:55:08,714 - 25m 44s (- 1m 44s) (6800 93%) 2.326383374655242\n",
            "2021-06-10 13:55:11,506 - 25m 47s (- 1m 20s) (6900 95%) 2.4840590699876395\n",
            "2021-06-10 13:55:14,206 - 25m 50s (- 0m 57s) (7000 96%) 2.3403105967629094\n",
            "2021-06-10 13:55:16,656 - 25m 52s (- 0m 34s) (7100 97%) 2.458174597809328\n",
            "2021-06-10 13:55:19,170 - 25m 55s (- 0m 12s) (7200 99%) 2.360315868642938\n",
            "2021-06-10 13:55:20,726 - EPOCH : 8\n",
            "2021-06-10 13:55:20,727 - ------------------------------\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "> [78, 105, 35, 35, 437, 271, 1]\n",
            "= [517, 415, 149, 1]\n",
            "< [85, 149, 149, 149, 1]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-06-10 13:55:23,494 - 25m 59s (- 1861m 1s) (100 1%) 4.116090071144946\n",
            "2021-06-10 13:55:26,166 - 26m 2s (- 919m 5s) (200 2%) 2.4104785887917886\n",
            "2021-06-10 13:55:28,865 - 26m 4s (- 605m 5s) (300 4%) 2.4405114292545993\n",
            "2021-06-10 13:55:31,606 - 26m 7s (- 448m 4s) (400 5%) 2.5158969150245163\n",
            "2021-06-10 13:55:34,508 - 26m 10s (- 353m 53s) (500 6%) 2.2657398938721784\n",
            "2021-06-10 13:55:37,382 - 26m 13s (- 291m 4s) (600 8%) 2.3485846250030518\n",
            "2021-06-10 13:55:40,065 - 26m 16s (- 246m 10s) (700 9%) 2.3215833249941804\n",
            "2021-06-10 13:55:43,005 - 26m 19s (- 212m 30s) (800 11%) 2.528535558272456\n",
            "2021-06-10 13:55:45,681 - 26m 21s (- 186m 17s) (900 12%) 2.479211424784389\n",
            "2021-06-10 13:55:48,393 - 26m 24s (- 165m 18s) (1000 13%) 2.314023787646386\n",
            "2021-06-10 13:55:50,920 - 26m 26s (- 148m 6s) (1100 15%) 2.265524129701895\n",
            "2021-06-10 13:55:53,689 - 26m 29s (- 133m 48s) (1200 16%) 2.2181097936898713\n",
            "2021-06-10 13:55:56,665 - 26m 32s (- 121m 41s) (1300 17%) 2.326039009992956\n",
            "2021-06-10 13:55:59,473 - 26m 35s (- 111m 18s) (1400 19%) 2.3930112685488787\n",
            "2021-06-10 13:56:02,607 - 26m 38s (- 102m 18s) (1500 20%) 2.4220530426299516\n",
            "2021-06-10 13:56:05,245 - 26m 41s (- 94m 24s) (1600 22%) 2.424261482018182\n",
            "2021-06-10 13:56:07,860 - 26m 43s (- 87m 25s) (1700 23%) 2.276055127815417\n",
            "2021-06-10 13:56:10,317 - 26m 46s (- 81m 12s) (1800 24%) 2.20735715749435\n",
            "2021-06-10 13:56:12,902 - 26m 48s (- 75m 38s) (1900 26%) 2.3140489416348666\n",
            "2021-06-10 13:56:15,701 - 26m 51s (- 70m 38s) (2000 27%) 2.3849029120100695\n",
            "2021-06-10 13:56:18,182 - 26m 54s (- 66m 6s) (2100 28%) 2.4932104337182563\n",
            "2021-06-10 13:56:20,895 - 26m 56s (- 61m 58s) (2200 30%) 2.3634025480118903\n",
            "2021-06-10 13:56:23,354 - 26m 59s (- 58m 12s) (2300 31%) 2.3567062232512854\n",
            "2021-06-10 13:56:26,284 - 27m 2s (- 54m 45s) (2400 33%) 2.36126517439025\n",
            "2021-06-10 13:56:29,086 - 27m 5s (- 51m 34s) (2500 34%) 2.2053614056498403\n",
            "2021-06-10 13:56:31,534 - 27m 7s (- 48m 37s) (2600 35%) 2.251268648180499\n",
            "2021-06-10 13:56:34,464 - 27m 10s (- 45m 53s) (2700 37%) 2.2123987682520534\n",
            "2021-06-10 13:56:37,200 - 27m 13s (- 43m 21s) (2800 38%) 2.3619204342564135\n",
            "2021-06-10 13:56:39,775 - 27m 15s (- 40m 59s) (2900 39%) 2.2363792392145116\n",
            "2021-06-10 13:56:42,632 - 27m 18s (- 38m 46s) (3000 41%) 2.2502785807597014\n",
            "2021-06-10 13:56:45,365 - 27m 21s (- 36m 42s) (3100 42%) 2.222630841418203\n",
            "2021-06-10 13:56:47,971 - 27m 23s (- 34m 45s) (3200 44%) 2.32224899886338\n",
            "2021-06-10 13:56:50,844 - 27m 26s (- 32m 56s) (3300 45%) 2.342009870363223\n",
            "2021-06-10 13:56:53,661 - 27m 29s (- 31m 12s) (3400 46%) 2.3248269629986007\n",
            "2021-06-10 13:56:56,410 - 27m 32s (- 29m 35s) (3500 48%) 2.2988215106952197\n",
            "2021-06-10 13:56:59,204 - 27m 35s (- 28m 2s) (3600 49%) 2.2607653023973366\n",
            "2021-06-10 13:57:01,701 - 27m 37s (- 26m 35s) (3700 50%) 2.422634648697133\n",
            "2021-06-10 13:57:04,471 - 27m 40s (- 25m 11s) (3800 52%) 2.3477142293355264\n",
            "2021-06-10 13:57:07,294 - 27m 43s (- 23m 53s) (3900 53%) 2.1636058002167684\n",
            "2021-06-10 13:57:09,953 - 27m 45s (- 22m 37s) (4000 55%) 2.3150157057875096\n",
            "2021-06-10 13:57:12,857 - 27m 48s (- 21m 26s) (4100 56%) 2.3371984895970024\n",
            "2021-06-10 13:57:15,487 - 27m 51s (- 20m 17s) (4200 57%) 2.2604105339106426\n",
            "2021-06-10 13:57:18,360 - 27m 54s (- 19m 12s) (4300 59%) 2.2074269942686167\n",
            "2021-06-10 13:57:20,734 - 27m 56s (- 18m 9s) (4400 60%) 2.2914688200999533\n",
            "2021-06-10 13:57:23,524 - 27m 59s (- 17m 10s) (4500 61%) 2.238651636344475\n",
            "2021-06-10 13:57:26,192 - 28m 2s (- 16m 12s) (4600 63%) 2.2240660665613534\n",
            "2021-06-10 13:57:29,303 - 28m 5s (- 15m 17s) (4700 64%) 2.159661935127292\n",
            "2021-06-10 13:57:32,365 - 28m 8s (- 14m 25s) (4800 66%) 2.230166992833671\n",
            "2021-06-10 13:57:35,102 - 28m 11s (- 13m 34s) (4900 67%) 2.2410716853707204\n",
            "2021-06-10 13:57:37,870 - 28m 13s (- 12m 45s) (5000 68%) 2.1793998484348354\n",
            "2021-06-10 13:57:40,597 - 28m 16s (- 11m 58s) (5100 70%) 2.268589918504982\n",
            "2021-06-10 13:57:42,964 - 28m 18s (- 11m 13s) (5200 71%) 2.2574603253111305\n",
            "2021-06-10 13:57:45,410 - 28m 21s (- 10m 29s) (5300 73%) 2.265679111318733\n",
            "2021-06-10 13:57:47,962 - 28m 23s (- 9m 46s) (5400 74%) 2.3982680003059964\n",
            "2021-06-10 13:57:50,771 - 28m 26s (- 9m 6s) (5500 75%) 2.162756150077941\n",
            "2021-06-10 13:57:53,331 - 28m 29s (- 8m 26s) (5600 77%) 2.2843675461015147\n",
            "2021-06-10 13:57:55,971 - 28m 31s (- 7m 48s) (5700 78%) 2.3190269789141142\n",
            "2021-06-10 13:57:58,697 - 28m 34s (- 7m 11s) (5800 79%) 2.112801761185791\n",
            "2021-06-10 13:58:01,552 - 28m 37s (- 6m 35s) (5900 81%) 2.221875235139512\n",
            "2021-06-10 13:58:04,379 - 28m 40s (- 6m 1s) (6000 82%) 2.2056997422666926\n",
            "2021-06-10 13:58:06,990 - 28m 43s (- 5m 27s) (6100 84%) 2.4208461512453705\n",
            "2021-06-10 13:58:09,434 - 28m 45s (- 4m 54s) (6200 85%) 2.304661470941099\n",
            "2021-06-10 13:58:12,231 - 28m 48s (- 4m 23s) (6300 86%) 2.3365010406901967\n",
            "2021-06-10 13:58:14,862 - 28m 50s (- 3m 52s) (6400 88%) 2.2753296238768015\n",
            "2021-06-10 13:58:17,823 - 28m 53s (- 3m 22s) (6500 89%) 2.1979028831451966\n",
            "2021-06-10 13:58:20,444 - 28m 56s (- 2m 53s) (6600 90%) 2.206865208069811\n",
            "2021-06-10 13:58:22,926 - 28m 58s (- 2m 25s) (6700 92%) 2.1120083719039884\n",
            "2021-06-10 13:58:25,677 - 29m 1s (- 1m 57s) (6800 93%) 2.2416805086590053\n",
            "2021-06-10 13:58:28,430 - 29m 4s (- 1m 31s) (6900 95%) 2.3850018923478786\n",
            "2021-06-10 13:58:31,081 - 29m 7s (- 1m 4s) (7000 96%) 2.1981691870857847\n",
            "2021-06-10 13:58:33,464 - 29m 9s (- 0m 39s) (7100 97%) 2.1938493151876095\n",
            "2021-06-10 13:58:35,942 - 29m 11s (- 0m 14s) (7200 99%) 2.195410749696863\n",
            "2021-06-10 13:58:37,467 - EPOCH : 9\n",
            "2021-06-10 13:58:37,469 - ------------------------------\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "> [157, 342, 78, 263, 1]\n",
            "= [42, 1]\n",
            "< [85, 1]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-06-10 13:58:40,198 - 29m 16s (- 2095m 45s) (100 1%) 3.762666727311568\n",
            "2021-06-10 13:58:42,821 - 29m 18s (- 1034m 47s) (200 2%) 2.25013328051563\n",
            "2021-06-10 13:58:45,546 - 29m 21s (- 681m 8s) (300 4%) 2.1988149271993573\n",
            "2021-06-10 13:58:48,267 - 29m 24s (- 504m 17s) (400 5%) 2.3035184720811634\n",
            "2021-06-10 13:58:51,149 - 29m 27s (- 398m 12s) (500 6%) 2.1183438489088653\n",
            "2021-06-10 13:58:54,008 - 29m 30s (- 327m 27s) (600 8%) 2.031365488803601\n",
            "2021-06-10 13:58:56,648 - 29m 32s (- 276m 52s) (700 9%) 2.103384647417431\n",
            "2021-06-10 13:58:59,520 - 29m 35s (- 238m 57s) (800 11%) 2.3300465892660984\n",
            "2021-06-10 13:59:02,142 - 29m 38s (- 209m 25s) (900 12%) 2.1462871467696827\n",
            "2021-06-10 13:59:04,794 - 29m 40s (- 185m 47s) (1000 13%) 2.1587809077386835\n",
            "2021-06-10 13:59:07,286 - 29m 43s (- 166m 26s) (1100 15%) 2.12869626633882\n",
            "2021-06-10 13:59:09,977 - 29m 46s (- 150m 19s) (1200 16%) 2.1162763845792854\n",
            "2021-06-10 13:59:12,914 - 29m 48s (- 136m 41s) (1300 17%) 2.1807125726274745\n",
            "2021-06-10 13:59:15,710 - 29m 51s (- 124m 59s) (1400 19%) 2.1771940521467625\n",
            "2021-06-10 13:59:18,741 - 29m 54s (- 114m 51s) (1500 20%) 2.166200954230824\n",
            "2021-06-10 13:59:21,405 - 29m 57s (- 105m 58s) (1600 22%) 2.1802204798296656\n",
            "2021-06-10 13:59:23,994 - 30m 0s (- 98m 7s) (1700 23%) 2.1456615663820466\n",
            "2021-06-10 13:59:26,444 - 30m 2s (- 91m 7s) (1800 24%) 2.091509935535043\n",
            "2021-06-10 13:59:29,031 - 30m 5s (- 84m 52s) (1900 26%) 2.210842229482696\n",
            "2021-06-10 13:59:31,816 - 30m 7s (- 79m 14s) (2000 27%) 2.19273260357877\n",
            "2021-06-10 13:59:34,225 - 30m 10s (- 74m 8s) (2100 28%) 2.2190357912501097\n",
            "2021-06-10 13:59:36,899 - 30m 12s (- 69m 29s) (2200 30%) 2.148823655173843\n",
            "2021-06-10 13:59:39,334 - 30m 15s (- 65m 14s) (2300 31%) 2.322812549986819\n",
            "2021-06-10 13:59:42,199 - 30m 18s (- 61m 21s) (2400 33%) 2.2010064944455454\n",
            "2021-06-10 13:59:44,957 - 30m 20s (- 57m 47s) (2500 34%) 2.0592014734177586\n",
            "2021-06-10 13:59:47,383 - 30m 23s (- 54m 28s) (2600 35%) 2.031836836207172\n",
            "2021-06-10 13:59:50,190 - 30m 26s (- 51m 24s) (2700 37%) 2.1105944589882233\n",
            "2021-06-10 13:59:52,972 - 30m 28s (- 48m 33s) (2800 38%) 2.1138506203464136\n",
            "2021-06-10 13:59:55,494 - 30m 31s (- 45m 53s) (2900 39%) 2.1941005334479518\n",
            "2021-06-10 13:59:58,289 - 30m 34s (- 43m 24s) (3000 41%) 2.130098635419504\n",
            "2021-06-10 14:00:01,008 - 30m 37s (- 41m 5s) (3100 42%) 2.0536832582830358\n",
            "2021-06-10 14:00:03,551 - 30m 39s (- 38m 53s) (3200 44%) 2.0562730768877207\n",
            "2021-06-10 14:00:06,337 - 30m 42s (- 36m 50s) (3300 45%) 2.076797856251338\n",
            "2021-06-10 14:00:09,075 - 30m 45s (- 34m 54s) (3400 46%) 2.084935553467891\n",
            "2021-06-10 14:00:11,791 - 30m 47s (- 33m 5s) (3500 48%) 2.1319324662684513\n",
            "2021-06-10 14:00:14,566 - 30m 50s (- 31m 21s) (3600 49%) 2.1447602529692076\n",
            "2021-06-10 14:00:17,058 - 30m 53s (- 29m 42s) (3700 50%) 2.267383810092483\n",
            "2021-06-10 14:00:19,805 - 30m 55s (- 28m 9s) (3800 52%) 2.149436715871751\n",
            "2021-06-10 14:00:22,551 - 30m 58s (- 26m 41s) (3900 53%) 1.9914029553919397\n",
            "2021-06-10 14:00:25,177 - 31m 1s (- 25m 16s) (4000 55%) 2.1415250302741797\n",
            "2021-06-10 14:00:28,052 - 31m 4s (- 23m 56s) (4100 56%) 2.1565738870487583\n",
            "2021-06-10 14:00:30,598 - 31m 6s (- 22m 39s) (4200 57%) 2.0785249312134173\n",
            "2021-06-10 14:00:33,383 - 31m 9s (- 21m 26s) (4300 59%) 1.9730734145712525\n",
            "2021-06-10 14:00:35,684 - 31m 11s (- 20m 16s) (4400 60%) 2.048953590377013\n",
            "2021-06-10 14:00:38,415 - 31m 14s (- 19m 9s) (4500 61%) 1.9712904375661175\n",
            "2021-06-10 14:00:41,041 - 31m 17s (- 18m 5s) (4600 63%) 2.0359686782847786\n",
            "2021-06-10 14:00:44,068 - 31m 20s (- 17m 4s) (4700 64%) 2.1191747696618823\n",
            "2021-06-10 14:00:47,074 - 31m 23s (- 16m 5s) (4800 66%) 1.9973987530410906\n",
            "2021-06-10 14:00:49,809 - 31m 25s (- 15m 8s) (4900 67%) 1.9908605267442818\n",
            "2021-06-10 14:00:52,590 - 31m 28s (- 14m 13s) (5000 68%) 1.9312962119425896\n",
            "2021-06-10 14:00:55,221 - 31m 31s (- 13m 20s) (5100 70%) 1.9443554765252529\n",
            "2021-06-10 14:00:57,616 - 31m 33s (- 12m 30s) (5200 71%) 2.06878630584042\n",
            "2021-06-10 14:01:00,067 - 31m 36s (- 11m 41s) (5300 73%) 2.180054672531249\n",
            "2021-06-10 14:01:02,639 - 31m 38s (- 10m 53s) (5400 74%) 2.229253407248395\n",
            "2021-06-10 14:01:05,523 - 31m 41s (- 10m 8s) (5500 75%) 2.0642735460095327\n",
            "2021-06-10 14:01:08,085 - 31m 44s (- 9m 24s) (5600 77%) 2.086201467679913\n",
            "2021-06-10 14:01:10,739 - 31m 46s (- 8m 41s) (5700 78%) 2.2521963599579187\n",
            "2021-06-10 14:01:13,444 - 31m 49s (- 8m 0s) (5800 79%) 1.9916813681141137\n",
            "2021-06-10 14:01:16,352 - 31m 52s (- 7m 20s) (5900 81%) 1.9395406967212496\n",
            "2021-06-10 14:01:19,166 - 31m 55s (- 6m 42s) (6000 82%) 2.0185448589242077\n",
            "2021-06-10 14:01:21,756 - 31m 57s (- 6m 4s) (6100 84%) 2.1157776570924582\n",
            "2021-06-10 14:01:24,143 - 32m 0s (- 5m 28s) (6200 85%) 2.2229659494440055\n",
            "2021-06-10 14:01:26,941 - 32m 2s (- 4m 53s) (6300 86%) 2.1502607681886547\n",
            "2021-06-10 14:01:29,528 - 32m 5s (- 4m 18s) (6400 88%) 2.1481259809583073\n",
            "2021-06-10 14:01:32,519 - 32m 8s (- 3m 45s) (6500 89%) 1.9076931220759779\n",
            "2021-06-10 14:01:35,081 - 32m 11s (- 3m 13s) (6600 90%) 2.0169870830903474\n",
            "2021-06-10 14:01:37,524 - 32m 13s (- 2m 41s) (6700 92%) 2.0293705917109643\n",
            "2021-06-10 14:01:40,207 - 32m 16s (- 2m 10s) (6800 93%) 1.9974118223796062\n",
            "2021-06-10 14:01:42,972 - 32m 18s (- 1m 41s) (6900 95%) 2.168798656558566\n",
            "2021-06-10 14:01:45,619 - 32m 21s (- 1m 12s) (7000 96%) 2.0227883114991947\n",
            "2021-06-10 14:01:48,010 - 32m 24s (- 0m 43s) (7100 97%) 2.0629216053715194\n",
            "2021-06-10 14:01:50,473 - 32m 26s (- 0m 16s) (7200 99%) 2.149924166259695\n",
            "2021-06-10 14:01:51,994 - TRAIN FINISHED\n",
            "2021-06-10 14:01:51,996 - ==================================================\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "> [52, 227, 200, 157, 402, 437, 1]\n",
            "= [365, 430, 199, 1]\n",
            "< [365, 430, 199, 1]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6YjN8pRTG5X"
      },
      "source": [
        "def corrects(encoder, decoder):#10):\n",
        "    corrects = 0\n",
        "    for i in range(len(datas['test_source.txt'])):\n",
        "        ran = random.randrange(1,len(datas['test_source.txt']))\n",
        "        pair = [datas['test_source.txt']['source'][ran], datas['test_target.txt']['target'][ran]]\n",
        "        output_words, attentions = evaluate(encoder, decoder, torch.Tensor(pair[0]).type(torch.long).unsqueeze(1))\n",
        "        if pair[1] == output_words:\n",
        "            corrects+=1\n",
        "    return corrects"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o14EoxfDchN4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a0cf1c8-96f7-41aa-eaba-6aae6e04ede7"
      },
      "source": [
        "torch.save(encoder1.state_dict(), './encoder_SGD.pth')\n",
        "torch.save(attn_decoder1.state_dict(), './attn_decoder_SGD.pth')\n",
        "logger.info(f\"MODEL SAVED as : encoder_SGD.pth , attn_decoder_SGD.pth\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-10 14:10:15,792 - MODEL SAVED as : encoder_SGD.pth , attn_decoder_SGD.pth\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOhe14DcvMAk",
        "outputId": "2ec88902-9e70-4556-c923-926da1f800ee"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.figure()\n",
        "fig, ax = plt.subplots()\n",
        "# 주기적인 간격에 이 locator가 tick을 설정\n",
        "loc = ticker.MultipleLocator(base=0.2)\n",
        "ax.yaxis.set_major_locator(loc)\n",
        "plt.plot(plot_losses)\n",
        "plt.show()\n",
        "plt.savefig('GRU_loss_SGD.png')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}