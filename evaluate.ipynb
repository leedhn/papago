{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "evaluate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPYo+BmJk4SuefqSy45flVS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leedhn/papago/blob/main/evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RenLIJQX1JIw",
        "outputId": "5146f8de-1e71-41da-8609-a98b42de2977"
      },
      "source": [
        "from google.colab import drive #edit\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/NAVER "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/NAVER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m6pdXjS1j4G"
      },
      "source": [
        "import pandas as pd #edit\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import random\n",
        "import logging\n",
        "import math\n",
        "import torchtext\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import Vocab\n",
        "from torchtext.utils import download_from_url, extract_archive\n",
        "from torch import Tensor\n",
        "import io\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkBawGff7vJD",
        "outputId": "45ba6155-08c9-4277-d285-c7999907ee7d"
      },
      "source": [
        "logger = logging.getLogger('my_logger')\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)\n",
        "logger.info('This message has a date/time timestamp')\n",
        "\n",
        "\n",
        "logger.propagate = False # do not pass logs to the default logger\n",
        "\n",
        "# Create handlers\n",
        "c_handler = logging.StreamHandler()\n",
        "EPOCH=10\n",
        "f_handler = logging.FileHandler(f'evaluate.log', mode='w')\n",
        "c_handler.setLevel(logging.INFO)\n",
        "f_handler.setLevel(logging.INFO)\n",
        "\n",
        "# Create formatters and add it to handlers\n",
        "c_format = logging.Formatter('%(asctime)s - %(message)s')\n",
        "f_format = logging.Formatter('%(asctime)s - %(message)s')\n",
        "c_handler.setFormatter(c_format)\n",
        "f_handler.setFormatter(f_format)\n",
        "\n",
        "# Add handlers to the logger\n",
        "logger.addHandler(c_handler)\n",
        "logger.addHandler(f_handler)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-10 12:39:45,566 - This message has a date/time timestamp\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beBKqd7r1oH1",
        "outputId": "68d9d29f-e9aa-4a17-f2ef-0198959301c0"
      },
      "source": [
        "%cd data\n",
        "txt_list = glob('*.txt') #edit\n",
        "datas = {}\n",
        "for txt in txt_list:\n",
        "    datas[txt] = pd.read_csv(txt,header=None)\n",
        "    name = txt[-10:-4]\n",
        "    datas[txt].columns = [name]\n",
        "    for i in range(len(datas[txt][name])):\n",
        "        datas[txt][name][i] = np.fromstring(datas[txt][name][i] ,dtype=int,sep=' ').tolist()\n",
        "        #datas[txt][name][i].append(1)\n",
        "    logger.info(f'Load {txt} finished')\n",
        "%cd ../"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'data'\n",
            "/content/drive/My Drive/NAVER/data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-06-10 12:39:47,736 - Load train_source.txt finished\n",
            "2021-06-10 12:39:48,740 - Load train_target.txt finished\n",
            "2021-06-10 12:39:49,236 - Load test_target.txt finished\n",
            "2021-06-10 12:39:49,641 - Load test_source.txt finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/NAVER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMce_og4158j"
      },
      "source": [
        "#%cd trained_model\n",
        "model_list = glob('trained_model/transformer*.pth')\n",
        "encoder_list = glob('trained_model/encoder*.pth')\n",
        "decoder_list = glob('trained_model/attn*.pth')\n",
        "#%cd ../"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9edDs61-2Iva"
      },
      "source": [
        "#Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tkI2b9-2E1H"
      },
      "source": [
        "torch.manual_seed(0)\n",
        "torch.use_deterministic_algorithms(True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "BATCH_SIZE = 128\n",
        "PAD_IDX = 3#de_vocab['<pad>']\n",
        "BOS_IDX = 2#de_vocab['<bos>']\n",
        "EOS_IDX = 1#de_vocab['<eos>']\n",
        "test_data_new = []\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7oDbtFD2PP7"
      },
      "source": [
        "# from torch.nn.utils.rnn import pad_sequence\n",
        "# from torch.utils.data import DataLoader\n",
        "\n",
        "# def generate_batch(data_batch):\n",
        "#   de_batch, en_batch = [], []\n",
        "#   for (de_item, en_item) in data_batch:\n",
        "    \n",
        "#     de_batch.append(torch.cat([torch.tensor([BOS_IDX]), de_item, torch.tensor([EOS_IDX])], dim=0))\n",
        "#     en_batch.append(torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0))\n",
        "#   de_batch = pad_sequence(de_batch, padding_value=PAD_IDX)#, batch_first=True)\n",
        "#   en_batch = pad_sequence(en_batch, padding_value=PAD_IDX)#, batch_first=True)\n",
        "\n",
        "#   return de_batch, en_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEwVqOyg2X33"
      },
      "source": [
        "\n",
        "for iter in range(len(datas['test_source.txt'])):\n",
        "    test_data_new.append((torch.Tensor(datas['test_source.txt']['source'][iter]).type(torch.long),torch.Tensor(datas['test_target.txt']['target'][iter]).type(torch.long)))\n",
        "\n",
        "# test_iter_new = DataLoader(test_data_new, batch_size=BATCH_SIZE,\n",
        "#                        shuffle=False, collate_fn=generate_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4hn62ha2cKc"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4fvscLD2bqm"
      },
      "source": [
        "from torch.nn import (TransformerEncoder, TransformerDecoder,\n",
        "                      TransformerEncoderLayer, TransformerDecoderLayer)\n",
        "\n",
        "\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self, num_encoder_layers: int, num_decoder_layers: int,\n",
        "                 emb_size: int, src_vocab_size: int, tgt_vocab_size: int,\n",
        "                 dim_feedforward:int = 512, dropout:float = 0.1):\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "        encoder_layer = TransformerEncoderLayer(d_model=emb_size, nhead=NHEAD,\n",
        "                                                dim_feedforward=dim_feedforward)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
        "        decoder_layer = TransformerDecoderLayer(d_model=emb_size, nhead=NHEAD,\n",
        "                                                dim_feedforward=dim_feedforward)\n",
        "        self.transformer_decoder = TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
        "                \n",
        "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
        "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n",
        "\n",
        "    def forward(self, src: Tensor, trg: Tensor, src_mask: Tensor,\n",
        "                tgt_mask: Tensor, src_padding_mask: Tensor,\n",
        "                tgt_padding_mask: Tensor, memory_key_padding_mask: Tensor):\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "        memory = self.transformer_encoder(src_emb, src_mask, src_padding_mask)\n",
        "        outs = self.transformer_decoder(tgt_emb, memory, tgt_mask, None,\n",
        "                                        tgt_padding_mask, memory_key_padding_mask)\n",
        "        return self.generator(outs)\n",
        "\n",
        "    def encode(self, src: Tensor, src_mask: Tensor):\n",
        "        return self.transformer_encoder(self.positional_encoding(\n",
        "                            self.src_tok_emb(src)), src_mask)\n",
        "\n",
        "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "        return self.transformer_decoder(self.positional_encoding(\n",
        "                          self.tgt_tok_emb(tgt)), memory,\n",
        "                          tgt_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24xkdMI42fN6"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, emb_size: int, dropout, maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding + \n",
        "                            self.pos_embedding[:token_embedding.size(0),:])\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IUvk0ab2g7i"
      },
      "source": [
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "def create_mask(src, tgt):\n",
        "  src_seq_len = src.shape[0]\n",
        "  tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "  tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "  src_mask = torch.zeros((src_seq_len, src_seq_len), device=DEVICE).type(torch.bool)\n",
        "\n",
        "  src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "  tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "  return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db8KzO382kDV"
      },
      "source": [
        "# SRC_VOCAB_SIZE = len(de_vocab)\n",
        "# TGT_VOCAB_SIZE = len(en_vocab)\n",
        "\n",
        "SRC_VOCAB_SIZE = 1000#len(de_vocab)\n",
        "TGT_VOCAB_SIZE = 1000#len(en_vocab)\n",
        "\n",
        "EMB_SIZE = 512\n",
        "NHEAD = 8\n",
        "FFN_HID_DIM = 512\n",
        "BATCH_SIZE = 128\n",
        "NUM_ENCODER_LAYERS = 3\n",
        "NUM_DECODER_LAYERS = 3\n",
        "NUM_EPOCHS = 16#64#16\n",
        "\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, \n",
        "                                 EMB_SIZE, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE,\n",
        "                                 FFN_HID_DIM)\n",
        "\n",
        "for p in transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "transformer = transformer.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_LBB_-w2pHv"
      },
      "source": [
        "#Evaluate Transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VELT53Oh8xW4"
      },
      "source": [
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    src = src.to(device)\n",
        "    src_mask = src_mask.to(device)\n",
        "\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n",
        "    for i in range(max_len-1):\n",
        "        memory = memory.to(device)\n",
        "        memory_mask = torch.zeros(ys.shape[0], memory.shape[0]).to(device).type(torch.bool)\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "                                    .type(torch.bool)).to(device)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim = 1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat([ys,\n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "        if next_word == EOS_IDX:\n",
        "          break\n",
        "    return ys\n",
        "    \n",
        "def translate(model, idx):\n",
        "  model.eval()\n",
        "  tokens = test_data_new[idx][0]\n",
        "  num_tokens = len(tokens)\n",
        "  src = (torch.LongTensor(tokens).reshape(num_tokens, 1) )\n",
        "  src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "  tgt_tokens = greedy_decode(model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "\n",
        "  return tokens.tolist(),test_data_new[idx][1].tolist(),tgt_tokens[1:-1].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg7UboxG4Ao7"
      },
      "source": [
        "def correct_num(model): #whole answer\n",
        "  model.eval()\n",
        "  corrects = 0\n",
        "  for idx in range(len(test_data_new)):\n",
        "    tokens = test_data_new[idx][0]\n",
        "    num_tokens = len(tokens)\n",
        "    src = (torch.LongTensor(tokens).reshape(num_tokens, 1) )\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = greedy_decode(model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "\n",
        "    if test_data_new[idx][1].tolist()==tgt_tokens[1:-1].tolist():\n",
        "        corrects +=1\n",
        "  return corrects"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiqCPsmI4C0o"
      },
      "source": [
        "def correct_num_wide(model): #sliced answer \n",
        "  model.eval()\n",
        "  corrects = 0\n",
        "  for idx in range(len(test_data_new)):\n",
        "    tokens = test_data_new[idx][0]\n",
        "    num_tokens = len(tokens)\n",
        "    src = (torch.LongTensor(tokens).reshape(num_tokens, 1) )\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = greedy_decode(model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "\n",
        "    if test_data_new[idx][1].tolist()==tgt_tokens[1:len(test_data_new[idx][1])+1].tolist():\n",
        "        corrects +=1\n",
        "  return corrects"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4J7qwM84lyi"
      },
      "source": [
        "def correct_num_vector(model): #sliced answer \n",
        "  model.eval()\n",
        "  corrects = 0\n",
        "  accuracy = 0.0\n",
        "  for idx in range(len(test_data_new)):\n",
        "    tokens = test_data_new[idx][0]\n",
        "    num_tokens = len(tokens)\n",
        "    src = (torch.LongTensor(tokens).reshape(num_tokens, 1) )\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = greedy_decode(model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "\n",
        "    tgt = test_data_new[idx][1].to(device)\n",
        "\n",
        "    for i in range(min(len(tgt),len(tgt_tokens)-1)):\n",
        "        \n",
        "        if tgt[i] == tgt_tokens[i+1]:\n",
        "            corrects +=1\n",
        "    cur_acc = corrects/max(len(tgt_tokens),len(tgt))\n",
        "    accuracy+=cur_acc\n",
        "    corrects = 0\n",
        "  \n",
        "  return accuracy/len(test_data_new)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DiQUTW_2tv1",
        "outputId": "882c3cc9-8c3d-4f78-f99e-f433ebf554a0"
      },
      "source": [
        "for model_path in model_list:\n",
        "    transformer = torch.load(model_path)\n",
        "    transformer.eval()\n",
        "    #acc_c = correct_num(transformer)\n",
        "    #acc_cw = correct_num_wide(transformer)\n",
        "    acc_v = correct_num_vector(transformer)\n",
        "    print(model_path,\"'s accuracy\")\n",
        "    #print(\"\",acc_c/len(test_data_new))\n",
        "    #print(\"\",acc_cw/len(test_data_new))\n",
        "    print(\"\",acc_v)\n",
        "    "
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trained_model/transformer.pth 's accuracy\n",
            " 0.2251138583720375\n",
            "trained_model/transformer_epoch32.pth 's accuracy\n",
            " 0.29049130928871736\n",
            "trained_model/transformer_no1.pth 's accuracy\n",
            " 0.41821483201269405\n",
            "trained_model/transformer_epoch_40.pth 's accuracy\n",
            " 0.4965256591883321\n",
            "trained_model/transformer_epoch_64.pth 's accuracy\n",
            " 0.5112848484506195\n",
            "trained_model/transformer_epoch_100.pth 's accuracy\n",
            " 0.5025680825309998\n",
            "trained_model/transformer_epoch_16.pth 's accuracy\n",
            " 0.42968025859986925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpK0IKh3IFQe"
      },
      "source": [
        "#Evaluate GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U66SENEdIH8p"
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Jj7y0LWIWY3"
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "MAX_LENGTH=100\n",
        "def evaluateGRU(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        encoder.eval()\n",
        "        decoder.eval()\n",
        "        #input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_tensor = sentence.to(device)#datas['test_source.txt']\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            # if topi.item() == EOS_token:\n",
        "            #     decoded_words.append('<EOS>')\n",
        "            #     break\n",
        "            # else:\n",
        "            #     decoded_words.append(output_lang.index2word[topi.item()])\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append(1)\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(topi.item())\n",
        "\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]\n",
        "\n",
        "import random\n",
        "def evaluateRandomly(encoder, decoder, n=1):#10):\n",
        "    for i in range(n):\n",
        "        ran = random.randrange(1,len(datas['test_source.txt']))\n",
        "        pair = [datas['test_source.txt']['source'][ran], datas['test_target.txt']['target'][ran]]\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluateGRU(encoder, decoder, torch.Tensor(pair[0]).type(torch.long).unsqueeze(1))\n",
        "        #output_sentence = ' '.join(output_words)\n",
        "        print('<',output_words)\n",
        "        #print('<', output_sentence)\n",
        "        print('')\n",
        "\n",
        "def corrects(encoder, decoder):\n",
        "\n",
        "    corrects = 0\n",
        "    for i in range(len(datas['test_source.txt'])):\n",
        "        ran = random.randrange(1,len(datas['test_source.txt']))\n",
        "        pair = [datas['test_source.txt']['source'][ran], datas['test_target.txt']['target'][ran]]\n",
        "        output_words, attentions = evaluateGRU(encoder, decoder, torch.Tensor(pair[0]).type(torch.long).unsqueeze(1))\n",
        "        if pair[1] == output_words:\n",
        "            corrects+=1\n",
        "    return corrects\n",
        "\n",
        "def corrects_wide(encoder, decoder): \n",
        "\n",
        "    corrects = 0\n",
        "\n",
        "    for i in range(len(datas['test_source.txt'])):\n",
        "        ran = random.randrange(1,len(datas['test_source.txt']))\n",
        "        pair = [datas['test_source.txt']['source'][ran], datas['test_target.txt']['target'][ran]]\n",
        "        output_words, attentions = evaluateGRU(encoder, decoder, torch.Tensor(pair[0]).type(torch.long).unsqueeze(1))\n",
        "        if pair[1] == output_words[:len(pair[1])]:\n",
        "            corrects+=1\n",
        "    return corrects\n",
        "\n",
        "\n",
        "def corrects_vector(encoder, decoder): \n",
        "\n",
        "    corrects = 0\n",
        "    accuracy = 0.0\n",
        "\n",
        "    for i in range(len(datas['test_source.txt'])):\n",
        "        ran = random.randrange(1,len(datas['test_source.txt']))\n",
        "        pair = [datas['test_source.txt']['source'][ran], datas['test_target.txt']['target'][ran]]\n",
        "        output_words, attentions = evaluateGRU(encoder, decoder, torch.Tensor(pair[0]).type(torch.long).unsqueeze(1))\n",
        "\n",
        "        for k in range(min(len(pair[1]),len(output_words))):\n",
        "\n",
        "            if pair[1][k] == output_words[k]:\n",
        "                corrects+=1\n",
        "        cur_acc = corrects/max(len(pair[1]),len(output_words))\n",
        "        accuracy+=cur_acc\n",
        "        corrects=0\n",
        "    return accuracy/len(datas['test_source.txt'])\n",
        "\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VQQ_8eJ8DsE"
      },
      "source": [
        "vars = ['Adam','SGD']\n",
        "hidden_size = 256\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "encoder1 = EncoderRNN(700, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, 700, dropout_p=0.1).to(device)\n",
        "for var in vars:\n",
        "    epath=''\n",
        "    dpath=''\n",
        "    for encoder_path in encoder_list:\n",
        "        if var in encoder_path:\n",
        "            encoder1.load_state_dict(torch.load(encoder_path))\n",
        "            epath=encoder_path\n",
        "            #print(encoder_path)\n",
        "            break\n",
        "    for decoder_path in decoder_list:\n",
        "        if var in decoder_path:\n",
        "            attn_decoder1.load_state_dict(torch.load(decoder_path))\n",
        "            dpath = decoder_path\n",
        "            break\n",
        "    encoder1.eval()\n",
        "    attn_decoder1.eval()\n",
        "    acc_c_gru = corrects(encoder1,attn_decoder1 )\n",
        "    acc_cw_gru = corrects_wide(encoder1,attn_decoder1)\n",
        "    acc_v_gru = corrects_vector(encoder1,attn_decoder1)\n",
        "    print(epath,dpath,\"'s accuracy\")\n",
        "    print(\"\",acc_c_gru/len(test_data_new))\n",
        "    print(\"\",acc_cw_gru/len(test_data_new))\n",
        "    print(\"\",acc_v_gru)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP4wsTF1TAlr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}